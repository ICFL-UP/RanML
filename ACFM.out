

Welcome to [92mRan[94mFor[91mRed

[0m
Your choices: 
Data:  False
Train:  [92mTrue[0m
Predict:  False
ROC:  False
CM:  False
BEST:  False
Models:  ['DT', 'KNN', 'RF', 'NN', 'NB', 'SVM', 'XGB', 'GBT', 'AB', 'KM', 'LR', 'BAG']
Please wait while things initialize ...
2024-08-21 20:14:51.211046
ACFM Dataset stats - Category: M    9540
B     592
Name: category, dtype: int64
ACFM Dataset stats - Label: 
0    10132
Name: label, dtype: int64
ACFM Dataset stats - Shape: (10132, 283)
Loading data ..
Dataset TRAIN ACFM: 
0    6079
Name: label, dtype: int64
Dataset VAL ACFM: 
0    2026
Name: label, dtype: int64
Dataset TEST ACFM: 
0    2027
Name: label, dtype: int64


Training Classifiers ...

Training RandomForrest for ACFM...
Fitting 10 folds for each of 54 candidates, totalling 540 fits
[CV 1/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 2/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 3/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 4/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 5/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 6/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 7/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 8/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 9/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5...............
[CV 10/10; 1/54] START criterion=gini, max_depth=2, n_estimators=5..............
[CV 1/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 2/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 3/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 4/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 5/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 6/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 7/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 8/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 9/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50..............
[CV 10/10; 2/54] START criterion=gini, max_depth=2, n_estimators=50.............
[CV 1/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 2/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 3/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 4/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 5/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 6/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 7/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 8/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 9/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250.............
[CV 10/10; 3/54] START criterion=gini, max_depth=2, n_estimators=250............
[CV 1/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 2/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 3/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 4/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 5/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 6/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 7/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 8/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 9/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5...............
[CV 10/10; 4/54] START criterion=gini, max_depth=4, n_estimators=5..............
[CV 1/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 2/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 3/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 4/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 5/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 6/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 7/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 8/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 9/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50..............
[CV 10/10; 5/54] START criterion=gini, max_depth=4, n_estimators=50.............
[CV 1/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 2/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 3/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 4/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 5/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 6/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 2/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   4.3s
[CV 7/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 10/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   5.3s
[CV 8/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 7/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   5.6s
[CV 9/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250.............
[CV 5/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.2s
[CV 10/10; 6/54] START criterion=gini, max_depth=4, n_estimators=250............
[CV 7/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   5.2s
[CV 1/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 1/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.4s
[CV 2/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 3/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.5s
[CV 3/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 4/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.5s
[CV 4/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 6/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.5s
[CV 5/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 10/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   5.2s
[CV 6/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 4/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   5.8s
[CV 7/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 2/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   6.1s
[CV 8/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 9/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   6.8s
[CV 9/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5...............
[CV 5/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   6.2s
[CV 10/10; 7/54] START criterion=gini, max_depth=8, n_estimators=5..............
[CV 6/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   6.2s
[CV 1/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 1/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   7.0s
[CV 2/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 8/10; 1/54] END criterion=gini, max_depth=2, n_estimators=5;, score=1.000 total time=   7.4s
[CV 3/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 8/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   6.1s
[CV 4/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 9/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   6.2s
[CV 5/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 3/10; 4/54] END criterion=gini, max_depth=4, n_estimators=5;, score=1.000 total time=   7.2s
[CV 6/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 2/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.8s
[CV 7/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 4/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.8s
[CV 8/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 7/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.7s
[CV 9/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50..............
[CV 5/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.9s
[CV 10/10; 8/54] START criterion=gini, max_depth=8, n_estimators=50.............
[CV 8/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.7s
[CV 1/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 6/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   2.9s
[CV 2/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 1/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   3.5s
[CV 3/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 9/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   3.1s
[CV 4/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 3/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   3.4s
[CV 5/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 10/10; 7/54] END criterion=gini, max_depth=8, n_estimators=5;, score=1.000 total time=   3.3s
[CV 6/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 3/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  20.6s
[CV 7/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 10/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  21.7s
[CV 8/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 5/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  21.9s
[CV 9/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250.............
[CV 2/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  20.3s
[CV 10/10; 9/54] START criterion=gini, max_depth=8, n_estimators=250............
[CV 7/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  22.0s
[CV 1/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 8/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  19.9s
[CV 2/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 4/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  22.2s
[CV 3/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 2/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  22.2s
[CV 4/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 1/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  22.4s
[CV 5/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 5/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.2s
[CV 6/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 4/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.3s
[CV 7/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 7/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.0s
[CV 8/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 10/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  20.7s
[CV 9/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5.............
[CV 3/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.5s
[CV 10/10; 10/54] START criterion=gini, max_depth=16, n_estimators=5............
[CV 8/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  23.3s
[CV 1/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 6/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  23.4s
[CV 2/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 9/10; 2/54] END criterion=gini, max_depth=2, n_estimators=50;, score=1.000 total time=  23.5s
[CV 3/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 1/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  22.1s
[CV 4/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 9/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.5s
[CV 5/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 6/10; 5/54] END criterion=gini, max_depth=4, n_estimators=50;, score=1.000 total time=  21.8s
[CV 6/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 4/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  16.7s
[CV 7/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 2/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.6s
[CV 8/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 1/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.7s
[CV 9/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50............
[CV 4/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.6s
[CV 10/10; 11/54] START criterion=gini, max_depth=16, n_estimators=50...........
[CV 1/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  17.6s
[CV 1/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 3/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.9s
[CV 2/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 9/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.0s
[CV 3/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 2/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  17.8s
[CV 4/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 5/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.8s
[CV 5/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 5/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  18.0s
[CV 6/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 7/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.8s
[CV 7/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 10/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.7s
[CV 8/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 3/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  18.5s
[CV 9/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250...........
[CV 6/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   2.9s
[CV 10/10; 12/54] START criterion=gini, max_depth=16, n_estimators=250..........
[CV 7/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  17.0s
[CV 1/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 8/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  17.1s
[CV 2/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 8/10; 10/54] END criterion=gini, max_depth=16, n_estimators=5;, score=1.000 total time=   3.4s
[CV 3/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 6/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  19.7s
[CV 4/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 9/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  18.4s
[CV 5/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 10/10; 8/54] END criterion=gini, max_depth=8, n_estimators=50;, score=1.000 total time=  18.9s
[CV 6/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 1/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   3.6s
[CV 7/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 2/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   3.4s
[CV 8/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 3/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   3.5s
[CV 9/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5.............
[CV 6/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.2s
[CV 10/10; 13/54] START criterion=gini, max_depth=32, n_estimators=5............
[CV 4/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.8s
[CV 1/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 5/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.8s
[CV 2/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 7/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   1.6s
[CV 3/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 9/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.0s
[CV 4/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 8/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.3s
[CV 5/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 10/10; 13/54] END criterion=gini, max_depth=32, n_estimators=5;, score=1.000 total time=   2.3s
[CV 6/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 5/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.1s
[CV 7/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 3/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.5s
[CV 8/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 1/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.9s
[CV 9/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50............
[CV 2/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.9s
[CV 10/10; 14/54] START criterion=gini, max_depth=32, n_estimators=50...........
[CV 4/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  18.4s
[CV 1/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 9/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.4s
[CV 2/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 10/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.4s
[CV 3/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 8/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  17.8s
[CV 4/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 6/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  18.9s
[CV 5/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 7/10; 11/54] END criterion=gini, max_depth=16, n_estimators=50;, score=1.000 total time=  18.9s
[CV 6/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 3/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  16.1s
[CV 7/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 2/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  17.1s
[CV 8/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 5/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  15.6s
[CV 9/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250...........
[CV 1/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  17.3s
[CV 10/10; 15/54] START criterion=gini, max_depth=32, n_estimators=250..........
[CV 4/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  17.4s
[CV 1/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 6/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  17.7s
[CV 2/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 1/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.0s
[CV 3/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 2/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.1s
[CV 4/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 3/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.2s
[CV 5/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 4/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   1.7s
[CV 6/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 5/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.0s
[CV 7/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 6/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 8/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 7/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  16.8s
[CV 9/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5...........
[CV 7/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 10/10; 16/54] START criterion=gini, max_depth=None, n_estimators=5..........
[CV 8/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.0s
[CV 1/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 9/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  16.9s
[CV 2/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 9/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   2.0s
[CV 3/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 10/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  18.5s
[CV 4/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 10/10; 16/54] END criterion=gini, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 5/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 8/10; 14/54] END criterion=gini, max_depth=32, n_estimators=50;, score=1.000 total time=  19.0s
[CV 6/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 2/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  15.4s
[CV 7/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 1/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  15.6s
[CV 8/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 4/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  14.8s
[CV 9/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50..........
[CV 6/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  14.8s
[CV 10/10; 17/54] START criterion=gini, max_depth=None, n_estimators=50.........
[CV 3/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  15.3s
[CV 1/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 5/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  15.6s
[CV 2/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 1/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 10/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 2/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 6/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 3/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 8/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 4/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250.........
[CV 5/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.5min
[CV 10/10; 18/54] START criterion=gini, max_depth=None, n_estimators=250........
[CV 8/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 1/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 4/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 6/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 7/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.5min
[CV 5/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 7/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 10/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 8/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  16.8s
[CV 8/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 7/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  16.9s
[CV 9/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5...........
[CV 2/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.5min
[CV 10/10; 19/54] START criterion=entropy, max_depth=2, n_estimators=5..........
[CV 5/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.5min
[CV 1/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 3/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.5min
[CV 2/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 3/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   1.7s
[CV 3/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 1/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.1s
[CV 4/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 5/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 9/10; 6/54] END criterion=gini, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 9/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  17.2s
[CV 7/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 4/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.4s
[CV 8/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 5/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.2s
[CV 9/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50..........
[CV 6/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 20/54] START criterion=entropy, max_depth=2, n_estimators=50.........
[CV 2/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.9s
[CV 1/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 4/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 10/10; 17/54] END criterion=gini, max_depth=None, n_estimators=50;, score=1.000 total time=  17.4s
[CV 3/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 9/10; 3/54] END criterion=gini, max_depth=2, n_estimators=250;, score=1.000 total time= 1.5min
[CV 4/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 10/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   1.9s
[CV 5/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 7/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.7s
[CV 6/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 8/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.8s
[CV 7/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 9/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   2.8s
[CV 8/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 6/10; 19/54] END criterion=entropy, max_depth=2, n_estimators=5;, score=1.000 total time=   3.0s
[CV 9/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250.........
[CV 2/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 21/54] START criterion=entropy, max_depth=2, n_estimators=250........
[CV 1/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.5min
[CV 1/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 3/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.5min
[CV 2/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 1/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.3s
[CV 3/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 2/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   1.7s
[CV 4/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 3/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   1.8s
[CV 5/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 4/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   1.7s
[CV 6/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 5/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.3s
[CV 7/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 6/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.0s
[CV 8/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 7/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   1.6s
[CV 9/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5...........
[CV 7/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 22/54] START criterion=entropy, max_depth=4, n_estimators=5..........
[CV 8/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.1s
[CV 1/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 9/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 4/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 10/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 10/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.0s
[CV 5/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 9/10; 22/54] END criterion=entropy, max_depth=4, n_estimators=5;, score=1.000 total time=   2.5s
[CV 6/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 8/10; 9/54] END criterion=gini, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 8/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 7/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50..........
[CV 5/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  16.8s
[CV 10/10; 23/54] START criterion=entropy, max_depth=4, n_estimators=50.........
[CV 1/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  17.8s
[CV 1/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 6/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 1/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 3/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  17.5s
[CV 4/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 2/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 6/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  17.2s
[CV 6/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 2/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  18.1s
[CV 7/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 7/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  17.3s
[CV 8/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 3/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250.........
[CV 9/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  18.5s
[CV 10/10; 24/54] START criterion=entropy, max_depth=4, n_estimators=250........
[CV 5/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 10/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 8/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  19.3s
[CV 3/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 10/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  19.2s
[CV 4/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 4/10; 20/54] END criterion=entropy, max_depth=2, n_estimators=50;, score=1.000 total time=  20.6s
[CV 5/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 3/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   2.8s
[CV 6/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 2/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   3.0s
[CV 7/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 4/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   2.9s
[CV 8/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 1/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   3.1s
[CV 9/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5...........
[CV 5/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   2.5s
[CV 10/10; 25/54] START criterion=entropy, max_depth=8, n_estimators=5..........
[CV 9/10; 12/54] END criterion=gini, max_depth=16, n_estimators=250;, score=1.000 total time= 1.5min
[CV 1/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 6/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   1.8s
[CV 2/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 9/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   1.7s
[CV 3/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 8/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   1.8s
[CV 4/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 7/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   2.0s
[CV 5/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 10/10; 25/54] END criterion=entropy, max_depth=8, n_estimators=5;, score=1.000 total time=   2.1s
[CV 6/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 1/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  16.8s
[CV 7/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 3/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 5/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  16.4s
[CV 9/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50..........
[CV 4/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  17.0s
[CV 10/10; 26/54] START criterion=entropy, max_depth=8, n_estimators=50.........
[CV 2/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  17.7s
[CV 1/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 6/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  17.4s
[CV 2/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 6/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 7/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  17.8s
[CV 4/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 3/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  19.3s
[CV 5/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 2/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 5/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 9/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  18.5s
[CV 8/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 8/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  19.4s
[CV 9/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250.........
[CV 4/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 27/54] START criterion=entropy, max_depth=8, n_estimators=250........
[CV 10/10; 23/54] END criterion=entropy, max_depth=4, n_estimators=50;, score=1.000 total time=  19.2s
[CV 1/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 1/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   3.0s
[CV 2/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 1/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.5min
[CV 3/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 9/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 7/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 2/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   1.9s
[CV 6/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 3/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   1.9s
[CV 7/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 4/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  17.3s
[CV 8/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 10/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5..........
[CV 5/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   1.8s
[CV 10/10; 28/54] START criterion=entropy, max_depth=16, n_estimators=5.........
[CV 8/10; 15/54] END criterion=gini, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 4/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.2s
[CV 2/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 2/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  18.2s
[CV 3/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 6/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  17.5s
[CV 4/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 5/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  18.2s
[CV 5/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 3/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  18.5s
[CV 6/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 6/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.0s
[CV 7/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 7/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.3s
[CV 8/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 1/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  19.6s
[CV 9/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50.........
[CV 8/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.4s
[CV 10/10; 29/54] START criterion=entropy, max_depth=16, n_estimators=50........
[CV 10/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.5s
[CV 1/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 9/10; 28/54] END criterion=entropy, max_depth=16, n_estimators=5;, score=1.000 total time=   2.7s
[CV 2/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 7/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  18.5s
[CV 3/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 8/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  18.7s
[CV 4/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 9/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  19.3s
[CV 5/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 10/10; 26/54] END criterion=entropy, max_depth=8, n_estimators=50;, score=1.000 total time=  19.3s
[CV 6/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 2/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  16.3s
[CV 7/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 3/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  16.2s
[CV 8/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 5/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  15.9s
[CV 9/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250........
[CV 10/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  15.6s
[CV 10/10; 30/54] START criterion=entropy, max_depth=16, n_estimators=250.......
[CV 4/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  17.3s
[CV 1/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 1/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  17.7s
[CV 2/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 8/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  17.1s
[CV 3/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 6/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  17.9s
[CV 4/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 7/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  18.0s
[CV 5/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 9/10; 29/54] END criterion=entropy, max_depth=16, n_estimators=50;, score=1.000 total time=  18.1s
[CV 6/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 1/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.6s
[CV 7/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 2/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.5s
[CV 8/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 3/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.0s
[CV 9/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5..........
[CV 4/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.3s
[CV 10/10; 31/54] START criterion=entropy, max_depth=32, n_estimators=5.........
[CV 5/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.2s
[CV 1/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 6/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.0s
[CV 2/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 7/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   1.9s
[CV 3/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 8/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.1s
[CV 4/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 9/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.4s
[CV 5/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 10/10; 31/54] END criterion=entropy, max_depth=32, n_estimators=5;, score=1.000 total time=   2.5s
[CV 6/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 1/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 2/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.5min
[CV 8/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 7/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50.........
[CV 3/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  14.0s
[CV 10/10; 32/54] START criterion=entropy, max_depth=32, n_estimators=50........
[CV 3/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 1/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  16.3s
[CV 2/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 4/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  15.0s
[CV 3/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 2/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  16.5s
[CV 4/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 4/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 6/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 6/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  15.8s
[CV 7/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 10/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 5/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  16.9s
[CV 9/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250........
[CV 5/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.5min
[CV 10/10; 33/54] START criterion=entropy, max_depth=32, n_estimators=250.......
[CV 9/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.5min
[CV 1/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 5/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 8/10; 18/54] END criterion=gini, max_depth=None, n_estimators=250;, score=1.000 total time= 1.5min
[CV 3/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 1/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.8s
[CV 4/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 7/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 1/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 2/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 7/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  16.9s
[CV 8/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 2/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.7s
[CV 9/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5........
[CV 3/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 34/54] START criterion=entropy, max_depth=None, n_estimators=5.......
[CV 4/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 9/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 3/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.8s
[CV 3/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 4/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 4/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 8/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 9/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.8s
[CV 6/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 5/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 7/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 7/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   2.1s
[CV 8/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 6/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 9/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50.......
[CV 10/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 10/10; 35/54] START criterion=entropy, max_depth=None, n_estimators=50......
[CV 8/10; 34/54] END criterion=entropy, max_depth=None, n_estimators=5;, score=1.000 total time=   2.4s
[CV 1/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 6/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.5min
[CV 2/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 10/10; 21/54] END criterion=entropy, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 8/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  18.5s
[CV 4/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 9/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  18.2s
[CV 5/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 10/10; 32/54] END criterion=entropy, max_depth=32, n_estimators=50;, score=1.000 total time=  19.1s
[CV 6/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 8/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 7/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 2/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250......
[CV 4/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 36/54] START criterion=entropy, max_depth=None, n_estimators=250.....
[CV 1/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  16.5s
[CV 1/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 9/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 6/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 3/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  16.7s
[CV 4/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 3/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 10/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 2/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  17.4s
[CV 7/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 4/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  17.0s
[CV 8/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 7/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  16.6s
[CV 9/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5..........
[CV 5/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.5min
[CV 10/10; 37/54] START criterion=log_loss, max_depth=2, n_estimators=5.........
[CV 9/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  16.7s
[CV 1/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 1/10; 24/54] END criterion=entropy, max_depth=4, n_estimators=250;, score=1.000 total time= 1.5min
[CV 2/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 8/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  16.9s
[CV 3/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 3/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   1.8s
[CV 4/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 5/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   1.8s
[CV 5/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 2/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.1s
[CV 6/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 1/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.5s
[CV 7/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 4/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.1s
[CV 8/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 6/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  17.9s
[CV 9/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50.........
[CV 6/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.2s
[CV 10/10; 38/54] START criterion=log_loss, max_depth=2, n_estimators=50........
[CV 10/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  17.9s
[CV 1/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 5/10; 35/54] END criterion=entropy, max_depth=None, n_estimators=50;, score=1.000 total time=  18.8s
[CV 2/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 7/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.6s
[CV 3/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 10/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.2s
[CV 4/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 9/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.5s
[CV 5/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 8/10; 37/54] END criterion=log_loss, max_depth=2, n_estimators=5;, score=1.000 total time=   2.8s
[CV 6/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 2/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 3/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 1/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250........
[CV 5/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 39/54] START criterion=log_loss, max_depth=2, n_estimators=250.......
[CV 9/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 7/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 10/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 4/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 6/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 2/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.1s
[CV 6/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 1/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.2s
[CV 7/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 3/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.0s
[CV 8/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 3/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  16.9s
[CV 9/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5..........
[CV 4/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   1.7s
[CV 10/10; 40/54] START criterion=log_loss, max_depth=4, n_estimators=5.........
[CV 2/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  16.9s
[CV 1/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 5/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   1.7s
[CV 2/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 5/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  16.5s
[CV 3/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 8/10; 27/54] END criterion=entropy, max_depth=8, n_estimators=250;, score=1.000 total time= 1.5min
[CV 4/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 8/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  16.6s
[CV 5/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 6/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   1.9s
[CV 6/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 7/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.0s
[CV 7/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 4/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  17.8s
[CV 8/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 6/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  17.7s
[CV 9/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50.........
[CV 1/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  18.6s
[CV 10/10; 41/54] START criterion=log_loss, max_depth=4, n_estimators=50........
[CV 9/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  17.6s
[CV 1/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 9/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.1s
[CV 2/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 8/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.6s
[CV 3/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 10/10; 40/54] END criterion=log_loss, max_depth=4, n_estimators=5;, score=1.000 total time=   2.6s
[CV 4/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 10/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  19.1s
[CV 5/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 7/10; 38/54] END criterion=log_loss, max_depth=2, n_estimators=50;, score=1.000 total time=  20.5s
[CV 6/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 1/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 2/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 3/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250........
[CV 4/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 42/54] START criterion=log_loss, max_depth=4, n_estimators=250.......
[CV 5/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 1/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.1s
[CV 2/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 2/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   1.5s
[CV 3/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 6/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.5min
[CV 4/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 4/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  16.9s
[CV 5/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 5/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  16.8s
[CV 6/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 3/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.4s
[CV 7/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 6/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  16.6s
[CV 8/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 7/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  16.4s
[CV 9/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5..........
[CV 7/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 43/54] START criterion=log_loss, max_depth=8, n_estimators=5.........
[CV 1/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.9s
[CV 1/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 2/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.8s
[CV 2/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 9/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.0s
[CV 3/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 3/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.2s
[CV 4/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 10/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.1s
[CV 5/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 8/10; 41/54] END criterion=log_loss, max_depth=4, n_estimators=50;, score=1.000 total time=  17.5s
[CV 6/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 6/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.1s
[CV 7/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 4/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.4s
[CV 8/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 8/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   1.9s
[CV 9/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50.........
[CV 9/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   1.9s
[CV 10/10; 44/54] START criterion=log_loss, max_depth=8, n_estimators=50........
[CV 5/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.4s
[CV 1/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 10/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.3s
[CV 2/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 7/10; 43/54] END criterion=log_loss, max_depth=8, n_estimators=5;, score=1.000 total time=   2.8s
[CV 3/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 10/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 9/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 8/10; 30/54] END criterion=entropy, max_depth=16, n_estimators=250;, score=1.000 total time= 1.5min
[CV 6/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 1/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  14.9s
[CV 7/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 5/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  15.2s
[CV 8/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 3/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  16.5s
[CV 9/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250........
[CV 4/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  16.6s
[CV 10/10; 45/54] START criterion=log_loss, max_depth=8, n_estimators=250.......
[CV 6/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  16.4s
[CV 1/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 2/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  17.5s
[CV 2/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 7/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  16.8s
[CV 3/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 8/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  17.4s
[CV 4/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 9/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  17.5s
[CV 5/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 2/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.8s
[CV 6/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 10/10; 44/54] END criterion=log_loss, max_depth=8, n_estimators=50;, score=1.000 total time=  17.9s
[CV 7/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 1/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   2.4s
[CV 8/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 3/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.7s
[CV 9/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5.........
[CV 5/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.5s
[CV 10/10; 46/54] START criterion=log_loss, max_depth=16, n_estimators=5........
[CV 4/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   2.0s
[CV 1/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 8/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.5s
[CV 2/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 6/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   2.1s
[CV 3/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 7/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   2.0s
[CV 4/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 9/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.8s
[CV 5/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 10/10; 46/54] END criterion=log_loss, max_depth=16, n_estimators=5;, score=1.000 total time=   1.8s
[CV 6/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 3/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 1/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 8/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50........
[CV 2/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 47/54] START criterion=log_loss, max_depth=16, n_estimators=50.......
[CV 5/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 10/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 6/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 7/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.5min
[CV 4/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 4/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.5min
[CV 5/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 9/10; 33/54] END criterion=entropy, max_depth=32, n_estimators=250;, score=1.000 total time= 1.5min
[CV 6/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 3/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 7/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 2/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 4/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250.......
[CV 1/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 48/54] START criterion=log_loss, max_depth=16, n_estimators=250......
[CV 3/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  16.6s
[CV 1/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 5/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 2/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  17.5s
[CV 3/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 1/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  17.7s
[CV 4/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 5/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  16.9s
[CV 5/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 6/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  16.5s
[CV 6/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 4/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  17.4s
[CV 7/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 1/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   1.7s
[CV 8/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 7/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  16.5s
[CV 9/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5.........
[CV 5/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   1.6s
[CV 10/10; 49/54] START criterion=log_loss, max_depth=32, n_estimators=5........
[CV 3/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   1.8s
[CV 1/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 4/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   1.9s
[CV 2/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 2/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   2.5s
[CV 3/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 7/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   1.9s
[CV 4/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 6/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   2.2s
[CV 5/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 8/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  17.7s
[CV 6/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 9/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  17.6s
[CV 7/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 10/10; 47/54] END criterion=log_loss, max_depth=16, n_estimators=50;, score=1.000 total time=  16.8s
[CV 8/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 8/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   2.2s
[CV 9/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50........
[CV 10/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   2.2s
[CV 10/10; 50/54] START criterion=log_loss, max_depth=32, n_estimators=50.......
[CV 9/10; 49/54] END criterion=log_loss, max_depth=32, n_estimators=5;, score=1.000 total time=   2.4s
[CV 1/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 6/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 7/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 8/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 9/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 1/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 10/10; 36/54] END criterion=entropy, max_depth=None, n_estimators=250;, score=1.000 total time= 1.5min
[CV 7/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 4/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 2/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250.......
[CV 5/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 51/54] START criterion=log_loss, max_depth=32, n_estimators=250......
[CV 3/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 6/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 1/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   2.6s
[CV 3/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 2/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 4/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 3/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   1.7s
[CV 5/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 4/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   1.9s
[CV 6/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 5/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   1.8s
[CV 7/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 6/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   1.7s
[CV 8/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 1/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.3s
[CV 9/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5.......
[CV 2/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.3s
[CV 10/10; 52/54] START criterion=log_loss, max_depth=None, n_estimators=5......
[CV 3/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.2s
[CV 1/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 4/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.1s
[CV 2/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 7/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  16.3s
[CV 3/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 8/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 4/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 9/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  16.5s
[CV 5/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 5/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.5s
[CV 6/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 8/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  16.8s
[CV 7/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 6/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.2s
[CV 8/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 7/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 9/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50......
[CV 7/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 53/54] START criterion=log_loss, max_depth=None, n_estimators=50.....
[CV 8/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 1/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 9/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 2/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 9/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   2.3s
[CV 3/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 10/10; 50/54] END criterion=log_loss, max_depth=32, n_estimators=50;, score=1.000 total time=  17.6s
[CV 4/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 10/10; 52/54] END criterion=log_loss, max_depth=None, n_estimators=5;, score=1.000 total time=   2.7s
[CV 5/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 10/10; 39/54] END criterion=log_loss, max_depth=2, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 7/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.3min
[CV 7/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 1/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 2/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 9/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250.....
[CV 3/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 54/54] START criterion=log_loss, max_depth=None, n_estimators=250....
[CV 4/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 5/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 6/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 8/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 3/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.6s
[CV 1/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.9s
[CV 9/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.0s
[CV 7/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.2s
[CV 2/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  17.0s
[CV 5/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.6s
[CV 10/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  16.1s
[CV 4/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  17.4s
[CV 6/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  17.2s
[CV 8/10; 53/54] END criterion=log_loss, max_depth=None, n_estimators=50;, score=1.000 total time=  17.2s
[CV 9/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 10/10; 42/54] END criterion=log_loss, max_depth=4, n_estimators=250;, score=1.000 total time= 1.4min
[CV 1/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 2/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 5/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 4/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 3/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 6/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.3min
[CV 7/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.2min
[CV 10/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.2min
[CV 8/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.2min
[CV 9/10; 45/54] END criterion=log_loss, max_depth=8, n_estimators=250;, score=1.000 total time= 1.2min
[CV 1/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 3/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 2/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 4/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 6/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 5/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 7/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.0min
[CV 9/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.0min
[CV 10/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.0min
[CV 8/10; 48/54] END criterion=log_loss, max_depth=16, n_estimators=250;, score=1.000 total time= 1.1min
[CV 1/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  55.6s
[CV 3/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  56.2s
[CV 4/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  55.1s
[CV 2/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  56.7s
[CV 6/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  51.6s
[CV 10/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  49.7s
[CV 5/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  54.4s
[CV 7/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  51.3s
[CV 9/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  50.1s
[CV 8/10; 51/54] END criterion=log_loss, max_depth=32, n_estimators=250;, score=1.000 total time=  50.5s
[CV 4/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  41.3s
[CV 2/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  41.9s
[CV 3/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  41.6s
[CV 1/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  42.2s
[CV 5/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  41.3s
[CV 6/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  38.7s
[CV 8/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  34.3s
[CV 10/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  32.5s
[CV 9/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  33.1s
[CV 7/10; 54/54] END criterion=log_loss, max_depth=None, n_estimators=250;, score=1.000 total time=  34.9s
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': None, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'gini', 'max_depth': None, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 32, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 32, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': 32, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 2, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 2, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 2, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 4, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 4, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 4, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 8, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 8, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 8, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 16, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 16, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 16, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 32, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 32, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': 32, 'n_estimators': 250}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': None, 'n_estimators': 5}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': None, 'n_estimators': 50}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'max_depth': None, 'n_estimators': 250}
BEST PARAMS for RandomForrest + ACFM: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 5}

Train time for Random Forrest + ACFM: 5.564473573366801 min

Training Gradient Boost for ACFM...
Fitting 10 folds for each of 180 candidates, totalling 1800 fits
[CV 1/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 2/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 4/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 5/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 6/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 7/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 8/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 1/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5
[CV 1/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 3/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 4/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 5/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 6/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 7/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 10/10; 2/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50
[CV 3/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 5/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 6/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 7/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 8/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 3/180] START learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250
[CV 1/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 4/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 8/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 3/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 7/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 8/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 10/10; 4/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 1/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 2/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 10/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 9/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 1/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 5/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50
[CV 1/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 5/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 2/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 8/10; 1/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 6/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 7/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 8/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 9/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 6/180] START learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 10/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.3s
[CV 2/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.3s
[CV 4/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 6/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 2/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.3s
[CV 8/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.3s
[CV 9/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 10/10; 7/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5
[CV 8/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 8/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
  u  pZ$  <  g     @@   @  J[\)[,P6Ǐl\ÛLD.=V      D       e3M                         0  Ѫ  x`  ڲ^[CV 7/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.3s
[CV 5/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 3/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 10/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 8/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50
[CV 1/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 6/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.3s
[CV 2/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 5/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 3/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 4/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 5/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 3/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 8/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 9/180] START learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250
[CV 1/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 9/10; 3/180] END learning_rate=0.01, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.3s
[CV 3/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 4/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 9/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 10/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 10/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5
[CV 8/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 6/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 5/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 1/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 4/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 1/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 7/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 7/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 11/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 4/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 3/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 10/10; 4/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.3s
[CV 7/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 6/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 8/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 4/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 12/180] START learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 7/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 2/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 7/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.3s
[CV 9/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 10/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 13/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 1/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 3/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 10/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 1/10; 6/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 6/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.2s
[CV 7/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 8/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 10/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 14/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50
[CV 6/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 7/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.3s
[CV 2/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 7/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.3s
[CV 3/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 9/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.4s
[CV 4/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 8/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 5/10; 5/180] END learning_rate=0.01, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.4s
[CV 6/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 3/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 5/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 8/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 1/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 7/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 15/180] START learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250
[CV 2/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.3s
[CV 1/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 5/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.2s
[CV 3/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 5/10; 8/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.3s
[CV 6/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 1/10; 9/180] END learning_rate=0.01, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.3s
[CV 7/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.2s
[CV 8/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 8/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 1/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.2s
  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@[CV 10/10; 16/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.2s
[CV 4/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 2/10; 10/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.3s
[CV 5/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 8/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.3s
[CV 8/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 2/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 17/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50
[CV 2/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.3s
[CV 1/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 3/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.2s
[CV 2/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 5/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.3s
[CV 4/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 3/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 8/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.3s
[CV 8/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 18/180] START learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250
[CV 10/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.3s
[CV 3/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.3s
[CV 5/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 5/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 7/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 5/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.3s
[CV 8/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.4s
[CV 9/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 7/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 10/10; 19/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5
[CV 3/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 1/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.3s
[CV 2/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 12/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.3s
[CV 3/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 4/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 6/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 6/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 3/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 7/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 8/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
   ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?     [CV 9/10; 20/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50
[CV 8/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 4/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 2/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 3/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 9/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 4/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 7/10; 13/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.3s
[CV 5/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 2/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 14/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.3s
[CV 7/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 21/180] START learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 1/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 5/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 3/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 7/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 5/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 10/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 6/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 7/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.3s
[CV 8/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 10/10; 22/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5
[CV 3/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 6/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 2/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.3s
[CV 6/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 3/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 8/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 8/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 23/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 15/180] END learning_rate=0.01, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.3s
[CV 10/10; 16/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.3s
[CV 9/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 3/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 4/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 5/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
                                                                                                                                                                                                                  [CV 2/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 7/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.3s
[CV 8/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 4/10; 18/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.3s
[CV 7/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 5/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 4/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 7/10; 17/180] END learning_rate=0.01, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.3s
[CV 3/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 8/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 2/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 8/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 19/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 24/180] START learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250
[CV 6/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 6/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 4/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 3/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 9/10; 21/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 4/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 1/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 5/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 6/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 8/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 20/180] END learning_rate=0.01, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 10/10; 22/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 10/10; 25/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5
[CV 9/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 2/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 3/10; 23/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 4/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 3/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
 loss=log_loss, max_depth=None, n_estimators=5
[CV 1/10; 11/180] END learning_rate=0.01, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.2s
  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P@  P[CV 6/10; 26/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50
[CV 2/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 2/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 8/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 4/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 10/10; 27/180] START learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 3/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 5/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 5/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 9/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 8/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 24/180] END learning_rate=0.01, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 28/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 4/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 25/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 29/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 2/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 1/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 3/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 26/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 9/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 8/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 2/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
                                                                                                                                                                                                                                                                                                                                                                            A           @              ?                  @@                  @  ?              @                      @          ?  ?       @  @              ?          @      @  ?              ?  @@          ?      A      @@                                                                                                         [CV 8/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 27/180] END learning_rate=0.01, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 1/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 30/180] START learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250
[CV 2/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 4/10; 29/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 28/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 5/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 7/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 10/10; 30/180] END learning_rate=0.01, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 8/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 1/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 31/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5
[CV 1/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 2/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 2/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 5/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 6/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 32/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 31/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 3/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 4/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 7/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
        learning_rate=learning_rate,
            n_estimators=n_estimators,
            criterion=criterion,
            [CV 3/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 33/180] START learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 32/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 3/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 7/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 3/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 9/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 33/180] END learning_rate=0.01, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 2/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 34/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 7/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 4/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 6/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 35/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50
[CV 2/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 2/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 34/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 3/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 5/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 5/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 9/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 36/180] START learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250
[CV 1/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 8/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 4/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 35/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 1/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 7/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 7/10; 36/180] END learning_rate=0.01, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 37/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5
[CV 1/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 3/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 4/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 3/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 6/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 7/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 5/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 10/10; 38/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 6/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 8/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 5/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 7/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 37/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 1/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 10/10; 39/180] START learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250
[CV 5/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 10/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 38/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 4/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 4/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 1/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 8/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 39/180] END learning_rate=0.1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 10/10; 40/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5
[CV 1/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 2/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 3/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 3/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 8/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 41/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50
[CV 1/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 4/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 6/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 40/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 9/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 42/180] START learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 41/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 1/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 6/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 9/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 8/10; 42/180] END learning_rate=0.1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 43/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5
[CV 1/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 3/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 3/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 8/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 10/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 9/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 44/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50
[CV 9/10; 43/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 1/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 3/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
                         4                                     0                .  .  .[CV 5/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 7/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 6/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 44/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 45/180] START learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250
[CV 6/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 3/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 4/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 6/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 9/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 10/10; 46/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 1/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 7/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 45/180] END learning_rate=0.1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 47/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50
[CV 1/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 46/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 5/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 5/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 8/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 48/180] START learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250
[CV 10/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 2/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 4/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 4/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 1/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 7/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 47/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 10/10; 49/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5
[CV 1/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 3/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 3/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 48/180] END learning_rate=0.1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 5/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 1/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 7/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 6/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 50/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50
[CV 1/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 2/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 1/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 3/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 9/10; 49/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 7/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 1/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 50/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 51/180] START learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250
[CV 2/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 4/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 5/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 8/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 52/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 8/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 3/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 7/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 51/180] END learning_rate=0.1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 6/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 7/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 5/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 3/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 53/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50
[CV 1/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 2/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 3/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 1/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 10/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 3/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 54/180] START learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250
[CV 1/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 8/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 2/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 9/10; 52/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 6/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 7/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 8/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 55/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 2/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 3/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 9/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 6/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 2/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 9/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 56/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50
[CV 3/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 5/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 4/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 7/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 7/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 5/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 9/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 8/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 57/180] START learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 3/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 6/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 7/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 4/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 53/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 6/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 58/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 54/180] END learning_rate=0.1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 8/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 55/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 56/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 3/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 57/180] END learning_rate=0.1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 10/10; 59/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50
[CV 1/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 2/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 58/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 2/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 5/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 6/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 3/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 6/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 7/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 60/180] START learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250
[CV 5/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 1/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 8/10; 59/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 6/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 6/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 3/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 9/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 61/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5
[CV 8/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 2/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 10/10; 60/180] END learning_rate=0.1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 4/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 1/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 6/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 2/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 5/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 4/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 10/10; 62/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50
[CV 1/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 3/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 61/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 63/180] START learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 62/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 8/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 8/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 9/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 64/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
             !       3M  3M  `       $        L                 D       U3M                              D       3M                 g           `@A  [CV 6/10; 63/180] END learning_rate=0.1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 4/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 2/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 6/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 8/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 65/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 3/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 64/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 3/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 6/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 7/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 6/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 8/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 9/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 65/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 66/180] START learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250
[CV 5/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 2/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 4/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 5/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 6/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 7/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 8/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 67/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5
[CV 4/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 2/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 5/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 6/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 10/10; 68/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50
[CV 10/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
                                                                                                                                                                                      [CV 2/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 4/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 2/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 3/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 10/10; 66/180] END learning_rate=0.1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 69/180] START learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 67/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 68/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 4/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 2/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 7/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 69/180] END learning_rate=0.1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 70/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 2/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 4/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 4/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 7/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 8/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 10/10; 71/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 7/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 1/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 70/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 3/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 72/180] START learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250
[CV 1/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 71/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 4/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 5/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 6/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 7/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 7/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 72/180] END learning_rate=0.1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 73/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5
[CV 1/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 4/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 4/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 6/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 6/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 7/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 10/10; 74/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 10/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 7/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 73/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 74/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 10/10; 75/180] START learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250
[CV 1/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 3/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 3/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
                      m                           &  \^  0zԪ   '  [CV 7/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 8/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 10/10; 76/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 75/180] END learning_rate=1, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 3/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 8/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 8/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 77/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50
[CV 10/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 4/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 76/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 4/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 5/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 5/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 7/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 8/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 9/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 78/180] START learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 9/10; 77/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 4/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 4/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 1/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 8/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 9/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 10/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 78/180] END learning_rate=1, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 79/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5
[CV 1/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 5/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 5/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 1/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 8/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 3/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 79/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 1/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 5/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 7/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 80/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 81/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 3/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 6/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 8/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 9/10; 81/180] END learning_rate=1, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 82/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 1/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 4/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 3/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 6/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 7/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 7/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 83/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50
[CV 8/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 10/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 5/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 82/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 4/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 8/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 84/180] START learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250
[CV 8/10; 80/180] START learning_rate=1, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 83/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 2/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 4/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 9/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 10/10; 85/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5
[CV 10/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 2/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 7/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 84/180] END learning_rate=1, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 6/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 7/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 2/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 10/10; 86/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50
[CV 1/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 1/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 3/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 5/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 6/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 7/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 8/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 87/180] START learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250
[CV 9/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 8/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 5/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 88/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5
[CV 4/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 1/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 3/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 3/10; 85/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 10/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 6/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 2/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [CV 5/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 89/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50
[CV 5/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 1/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 2/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 4/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 1/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 10/10; 90/180] START learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250
[CV 8/10; 86/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 2/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 6/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 8/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 7/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 8/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 6/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 87/180] END learning_rate=1, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 91/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 88/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 89/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 1/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 6/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 90/180] END learning_rate=1, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 9/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 10/10; 92/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=50
[CV 3/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 91/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 5/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 4/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 8/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 93/180] START learning_rate=1, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 3/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 4/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 92/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 5/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 5/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 6/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 9/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 10/10; 94/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 10/10; 93/180] END learning_rate=1, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 3/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 8/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 8/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 95/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 6/10; 94/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 3/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 6/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 5/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 7/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 95/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 96/180] START learning_rate=1, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 2/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 3/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 4/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 7/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 8/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 4/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 3/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 97/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=5
[CV 6/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 9/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 10/10; 96/180] END learning_rate=1, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 7/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 6/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 3/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 9/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 97/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 98/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=50
[CV 1/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 2/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 3/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 1/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 10/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 99/180] START learning_rate=1, loss=exponential, max_depth=8, n_estimators=250
[CV 1/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 98/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 3/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 5/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 9/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 8/10; 99/180] END learning_rate=1, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 100/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 6/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 5/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 5/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 8/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 100/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 101/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=50
[CV 4/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 6/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 5/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 5/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 6/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 7/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 8/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 9/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 102/180] START learning_rate=1, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 2/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 4/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 5/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 6/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 1/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 8/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 101/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 10/10; 103/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=5
[CV 1/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 5/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 6/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 1/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 102/180] END learning_rate=1, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 104/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=50
[CV 1/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 103/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 3/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 4/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 2/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 8/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 10/10; 104/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 105/180] START learning_rate=1, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 3/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 2/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 6/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 7/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 9/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 106/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=5
[CV 4/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 2/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 4/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 6/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 105/180] END learning_rate=1, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 10/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 8/10; 106/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 10/10; 107/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 2/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 4/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 4/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 5/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
                                                                                                                                                                                                                                                                                                          [CV 5/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 7/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 7/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 108/180] START learning_rate=1, loss=exponential, max_depth=None, n_estimators=250
[CV 1/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 6/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 5/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 107/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 5/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 2/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 109/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5
[CV 8/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 6/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 10/10; 108/180] END learning_rate=1, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 110/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50
[CV 7/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 109/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 5/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 8/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 10/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 6/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 110/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 111/180] START learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250
[CV 1/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 2/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 8/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 7/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 111/180] END learning_rate=10, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 1/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 112/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5
[CV 2/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 2/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 3/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 10/10; 113/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50
[CV 1/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 112/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 7/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 4/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 7/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 8/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 9/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 113/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 114/180] START learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 4/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 4/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 9/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 8/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 10/10; 115/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 114/180] END learning_rate=10, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 1/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 3/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 3/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 8/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 7/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 10/10; 116/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50
[CV 5/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 8/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 4/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 5/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 115/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 5/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 7/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 1/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 116/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 117/180] START learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250
[CV 1/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 4/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 3/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 4/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 6/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 6/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 9/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 3/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 118/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 117/180] END learning_rate=10, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 3/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 4/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 5/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 6/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 6/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 8/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 8/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 119/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 118/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 1/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 3/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 6/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 6/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 10/10; 120/180] START learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250
[CV 1/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 9/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 119/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 3/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 7/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 7/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 9/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 9/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 121/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5
[CV 1/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 2/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 3/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 5/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 6/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 7/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 10/10; 122/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50
[CV 1/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 2/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 3/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 120/180] END learning_rate=10, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 7/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 5/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 3/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 123/180] START learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250
[CV 8/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 5/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 124/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 121/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 122/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 9/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 10/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 8/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 123/180] END learning_rate=10, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 2/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 6/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 8/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 7/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 10/10; 124/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 125/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50
[CV 1/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 2/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 4/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 4/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 5/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 2/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 3/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 10/10; 126/180] START learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 2/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 7/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 4/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 125/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 2/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 9/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 10/10; 127/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=5
[CV 9/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 2/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 1/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 126/180] END learning_rate=10, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 3/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 8/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 6/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 10/10; 128/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=50
[CV 9/10; 127/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 4/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 5/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 6/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 9/10; 128/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 10/10; 129/180] START learning_rate=10, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 6/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 3/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 4/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 7/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 7/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 9/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 9/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 130/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=5
[CV 1/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 3/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 129/180] END learning_rate=10, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 6/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 8/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 10/10; 131/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 130/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 2/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 3/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 5/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 4/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 7/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 131/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 132/180] START learning_rate=10, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 2/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 3/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 1/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 2/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 8/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 9/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 10/10; 133/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=5
[CV 1/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 2/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 4/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 4/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 5/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 6/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 7/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 9/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 3/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 134/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=50
[CV 1/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 2/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 1/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 4/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 8/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 10/10; 135/180] START learning_rate=10, loss=exponential, max_depth=8, n_estimators=250
[CV 1/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 3/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 132/180] END learning_rate=10, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 3/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 136/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 6/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 134/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 133/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 6/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 135/180] END learning_rate=10, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 5/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 5/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 136/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 137/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 2/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 3/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 5/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 6/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 7/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 9/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 138/180] START learning_rate=10, loss=exponential, max_depth=16, n_estimators=250
[CV 9/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 10/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 7/10; 137/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 5/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 6/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 1/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 8/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 139/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
                                                                                                                                                                                                                  [CV 2/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 8/10; 138/180] END learning_rate=10, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 2/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 8/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 139/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 140/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=50
[CV 1/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 3/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 4/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 8/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 10/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 7/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 7/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 140/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 141/180] START learning_rate=10, loss=exponential, max_depth=32, n_estimators=250
[CV 2/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 2/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 3/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 6/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 7/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 6/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 142/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 10/10; 141/180] END learning_rate=10, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 2/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 7/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 6/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 7/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 143/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
                                                                                           [CV 4/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 142/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 7/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 144/180] START learning_rate=10, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 143/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 2/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 1/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 6/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 6/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 3/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 5/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 9/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 145/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5
[CV 10/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 2/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 5/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 144/180] END learning_rate=10, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 7/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 8/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 9/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 10/10; 146/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50
[CV 1/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 4/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 8/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 5/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 7/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 9/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 145/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 8/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 2/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 1/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 147/180] START learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250
[CV 3/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [CV 8/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 2/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 7/10; 146/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 5/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 6/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 9/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 10/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 147/180] END learning_rate=100, loss=log_loss, max_depth=2, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 148/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5
[CV 3/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 2/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 3/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 4/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 5/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 8/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 7/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 6/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 149/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50
[CV 9/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 148/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 2/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 3/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 4/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 10/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 8/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 9/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 149/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 150/180] START learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250
[CV 1/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 2/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 4/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 5/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 3/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 6/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
_@Q      P09  f-9          4       @19  s09                0       !       09   09  p       D       `*09                 ]           _@A        '09  pi09          !       `/9  909  [CV 9/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 7/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 151/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5
[CV 1/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 2/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 150/180] END learning_rate=100, loss=log_loss, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 10/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 4/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 6/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 8/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 5/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 10/10; 152/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50
[CV 8/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 9/10; 151/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 6/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 6/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 8/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 8/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 4/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 10/10; 153/180] START learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250
[CV 2/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 152/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 3/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 5/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 7/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 6/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 153/180] END learning_rate=100, loss=log_loss, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 8/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 2/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 10/10; 154/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5
[CV 1/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 2/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 3/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 6/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 5/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 5/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 7/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 8/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 9/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 155/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50
[CV 10/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 1/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 154/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 4/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 5/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 6/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 7/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 2/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 4/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 10/10; 156/180] START learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250
[CV 9/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 6/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 8/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 155/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 1/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 7/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 5/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 4/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 8/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 157/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5
[CV 9/10; 156/180] END learning_rate=100, loss=log_loss, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 2/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 3/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 2/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 5/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 3/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 8/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 9/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 158/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50
[CV 4/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 157/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 6/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 4/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 5/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 6/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 8/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 9/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 10/10; 159/180] START learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250
[CV 1/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 3/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 6/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 7/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 9/10; 158/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 2/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 10/10; 160/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5
[CV 1/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 1/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 3/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 5/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 6/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 7/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 8/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 4/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 5/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 161/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50
[CV 1/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 6/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 10/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 5/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 7/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 4/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 1/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 162/180] START learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250
[CV 9/10; 159/180] END learning_rate=100, loss=log_loss, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 2/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 3/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 6/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 5/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 6/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 8/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 3/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 9/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 163/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=5
[CV 1/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 5/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 10/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 6/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 7/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 8/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 9/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 10/10; 164/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=50
[CV 4/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 7/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
                                                                                          [CV 2/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 5/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 8/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 7/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 3/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 2/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 165/180] START learning_rate=100, loss=exponential, max_depth=2, n_estimators=250
[CV 1/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 6/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 4/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 8/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 5/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 9/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 5/10; 160/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 7/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 10/10; 166/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=5
[CV 2/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 1/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 10/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 6/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 5/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 10/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 7/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 2/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 9/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 3/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 167/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=50
[CV 4/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 2/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 161/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=50;, score=nan total time=   0.2s
[CV 3/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 4/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 5/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 4/10; 162/180] END learning_rate=100, loss=log_loss, max_depth=None, n_estimators=250;, score=nan total time=   0.2s
[CV 6/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 2/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 3/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.1s
[CV 8/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 9/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 1/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 168/180] START learning_rate=100, loss=exponential, max_depth=4, n_estimators=250
[CV 10/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 4/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 5/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 3/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 1/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 4/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 3/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 9/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
[CV 4/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 7/10; 169/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=5
                                                                                                                                                                                                                                                                                                                [CV 7/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 1/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 5/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 6/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 9/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 9/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 5/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 6/10; 163/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 7/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 7/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 9/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 8/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 10/10; 170/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=50
[CV 5/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 1/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 1/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.1s
[CV 2/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 3/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 4/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 4/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 6/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 9/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 7/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 8/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 5/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 7/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 165/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=250;, score=nan total time=   0.2s
[CV 7/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 10/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.1s
[CV 6/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 10/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 2/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 164/180] END learning_rate=100, loss=exponential, max_depth=2, n_estimators=50;, score=nan total time=   0.3s
[CV 10/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 10/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 1/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 4/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 8/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 166/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=5;, score=nan total time=   0.2s
[CV 10/10; 171/180] START learning_rate=100, loss=exponential, max_depth=8, n_estimators=250
[CV 6/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 2/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 4/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 1/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 5/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [CV 3/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 2/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 6/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s

[CV 3/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 6/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 9/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 8/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 4/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 4/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 5/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 3/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 6/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 2/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 7/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 7/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 167/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=50;, score=nan total time=   0.2s
[CV 5/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 9/10; 168/180] END learning_rate=100, loss=exponential, max_depth=4, n_estimators=250;, score=nan total time=   0.2s
[CV 9/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 10/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 1/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 8/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.1s
[CV 3/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 170/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 171/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 169/180] END learning_rate=100, loss=exponential, max_depth=8, n_estimators=5;, score=nan total time=   0.2s
[CV 9/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 10/10; 172/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=5
[CV 1/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 2/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 3/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 4/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 5/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 6/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 9/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 7/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 8/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 9/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 10/10; 173/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=50
[CV 1/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 172/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 1/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 4/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 2/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 4/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 3/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 7/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 7/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 8/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 8/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 9/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 9/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 10/10; 173/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=50;, score=nan total time=   0.1s
[CV 10/10; 174/180] START learning_rate=100, loss=exponential, max_depth=16, n_estimators=250
[CV 1/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 2/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 2/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 5/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 3/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 4/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 4/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 6/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 1/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.1s
[CV 5/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 6/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 10/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 8/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 9/10; 174/180] END learning_rate=100, loss=exponential, max_depth=16, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 2/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 10/10; 175/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=5
[CV 3/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 4/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 3/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 5/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 5/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 6/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 6/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 9/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 10/10; 176/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=50
[CV 7/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 1/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 9/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 3/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 4/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 5/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 8/10; 175/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=5;, score=nan total time=   0.0s
[CV 3/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 6/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 8/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 8/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 7/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 177/180] START learning_rate=100, loss=exponential, max_depth=32, n_estimators=250
[CV 1/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 1/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.0s
[CV 2/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 3/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 4/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 5/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 10/10; 176/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=50;, score=nan total time=   0.1s
[CV 3/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 4/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 8/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 2/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.1s
[CV 6/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 178/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=5
[CV 9/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 177/180] END learning_rate=100, loss=exponential, max_depth=32, n_estimators=250;, score=nan total time=   0.0s
[CV 1/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 2/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 3/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 4/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 6/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 5/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 5/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 6/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 7/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 10/10; 178/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=5;, score=nan total time=   0.0s
[CV 8/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 9/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 2/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 179/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=50
[CV 1/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 2/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 1/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 4/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 3/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 6/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 4/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 9/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 5/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 1/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 7/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 9/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 10/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 10/10; 180/180] START learning_rate=100, loss=exponential, max_depth=None, n_estimators=250
[CV 8/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 6/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 6/10; 179/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=50;, score=nan total time=   0.0s
[CV 3/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 2/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 5/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 4/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 8/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 7/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 10/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
[CV 9/10; 180/180] END learning_rate=100, loss=exponential, max_depth=None, n_estimators=250;, score=nan total time=   0.0s
None





ERROR in training of DT





Training AdaBoost for ACFM...
Fitting 10 folds for each of 15 candidates, totalling 150 fits
[CV 1/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 2/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 3/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 4/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 5/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 6/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 7/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 8/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 9/10; 1/15] START learning_rate=0.01, n_estimators=5........................
[CV 10/10; 1/15] START learning_rate=0.01, n_estimators=5.......................
[CV 1/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 2/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 3/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 4/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 5/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 6/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 7/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 8/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 9/10; 2/15] START learning_rate=0.01, n_estimators=50.......................
[CV 10/10; 2/15] START learning_rate=0.01, n_estimators=50......................
[CV 1/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 2/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 3/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 4/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 5/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 6/10; 3/15] START learning_rate=0.01, n_estimators=250......................
                                                                                                                                                                                                                                                                                                                                                   [CV 7/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 8/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 9/10; 3/15] START learning_rate=0.01, n_estimators=250......................
[CV 10/10; 3/15] START learning_rate=0.01, n_estimators=250.....................
[CV 1/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 2/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 3/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 4/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 5/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 6/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 7/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 8/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 9/10; 4/15] START learning_rate=0.1, n_estimators=5.........................
[CV 10/10; 4/15] START learning_rate=0.1, n_estimators=5........................
[CV 1/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 2/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 3/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 4/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 1/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.3s
[CV 5/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 6/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 7/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 8/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 9/10; 5/15] START learning_rate=0.1, n_estimators=50........................
[CV 10/10; 5/15] START learning_rate=0.1, n_estimators=50.......................
[CV 9/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.3s
[CV 1/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 2/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 5/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.3s
[CV 3/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 4/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 5/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 6/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 6/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 7/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 3/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 8/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 4/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 9/10; 6/15] START learning_rate=0.1, n_estimators=250.......................
[CV 10/10; 6/15] START learning_rate=0.1, n_estimators=250......................
[CV 1/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 2/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 8/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s
[CV 3/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 3/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s
[CV 4/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 7/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 5/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 8/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 6/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 4/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.4s
[CV 7/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 1/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s
[CV 8/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 2/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.4s
[CV 9/10; 7/15] START learning_rate=1, n_estimators=5...........................
[CV 7/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s
[CV 10/10; 7/15] START learning_rate=1, n_estimators=5..........................
[CV 10/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.5s
[CV 1/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 1/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.4s
[CV 2/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 3/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.4s
[CV 3/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 9/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.5s
[CV 4/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 5/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.5s
[CV 5/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 9/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.4s
[CV 6/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 4/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.5s
[CV 7/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 2/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.6s
[CV 8/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 8/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.5s
[CV 9/10; 8/15] START learning_rate=1, n_estimators=50..........................
[CV 9/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.4s
[CV 10/10; 8/15] START learning_rate=1, n_estimators=50.........................
[CV 2/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.6s
[CV 1/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 6/10; 2/15] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.6s
[CV 2/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 7/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.5s
[CV 3/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 10/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.6s
[CV 4/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 3/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.4s
[CV 5/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 4/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.5s
[CV 6/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 6/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.5s
[CV 7/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 5/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 8/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 3/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 9/10; 9/15] START learning_rate=1, n_estimators=250.........................
[CV 5/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.6s
[CV 10/10; 9/15] START learning_rate=1, n_estimators=250........................
[CV 2/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.5s
[CV 1/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 1/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 2/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 5/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.5s
[CV 3/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 1/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 4/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 6/10; 3/15] END learning_rate=0.01, n_estimators=250;, score=1.000 total time=   0.7s
[CV 5/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 10/10; 1/15] END learning_rate=0.01, n_estimators=5;, score=1.000 total time=   0.8s
[CV 6/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 2/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.7s
[CV 7/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 4/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.4s
[CV 8/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 7/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 9/10; 10/15] START learning_rate=10, n_estimators=5.........................
[CV 8/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 10/10; 10/15] START learning_rate=10, n_estimators=5........................
[CV 6/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.4s
[CV 1/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 6/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 2/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 10/10; 4/15] END learning_rate=0.1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 3/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 4/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 4/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 8/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.5s
[CV 5/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 8/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 6/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 2/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.5s
[CV 7/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 5/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.4s
[CV 8/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 2/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 9/10; 11/15] START learning_rate=10, n_estimators=50........................
[CV 7/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 10/10; 11/15] START learning_rate=10, n_estimators=50.......................
[CV 5/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 1/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 9/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 2/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 1/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.6s
[CV 3/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 3/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 4/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 9/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 5/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 7/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 6/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 1/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.7s
[CV 7/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 10/10; 5/15] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 8/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 4/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.7s
[CV 9/10; 12/15] START learning_rate=10, n_estimators=250.......................
[CV 7/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.7s
[CV 10/10; 12/15] START learning_rate=10, n_estimators=250......................
[CV 3/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 1/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 5/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.7s
[CV 2/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 8/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.5s
[CV 3/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 10/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.7s
[CV 4/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 6/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 5/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 8/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.8s
[CV 6/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 9/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.7s
[CV 7/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 7/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 8/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 1/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 9/10; 13/15] START learning_rate=100, n_estimators=5........................
[CV 2/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 10/10; 13/15] START learning_rate=100, n_estimators=5.......................
[CV 6/10; 6/15] END learning_rate=0.1, n_estimators=250;, score=1.000 total time=   0.8s
[CV 1/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 3/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.8s
[CV 2/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 1/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.5s
[CV 3/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 4/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.7s
[CV 4/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 10/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.5s
[CV 5/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 10/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.6s
[CV 6/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 7/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.5s
[CV 7/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 5/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.5s
[CV 8/10; 14/15] START learning_rate=100, n_estimators=50.......................
[CV 10/10; 7/15] END learning_rate=1, n_estimators=5;, score=1.000 total time=   0.8s
[CV 10/10; 14/15] START learning_rate=100, n_estimators=50......................
[CV 9/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 1/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 1/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.6s
[CV 2/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 8/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.6s
[CV 3/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 5/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.5s
[CV 4/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 3/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.7s
[CV 5/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 9/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.5s
[CV 6/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 3/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.6s
[CV 7/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 10/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.5s
[CV 8/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 2/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.5s
[CV 9/10; 15/15] START learning_rate=100, n_estimators=250......................
[CV 6/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.7s
[CV 10/10; 15/15] START learning_rate=100, n_estimators=250.....................
[CV 6/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.6s
[CV 9/10; 8/15] END learning_rate=1, n_estimators=50;, score=1.000 total time=   0.8s
[CV 9/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.5s
[CV 8/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.6s
[CV 5/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.5s
[CV 2/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 7/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.6s
[CV 4/10; 9/15] END learning_rate=1, n_estimators=250;, score=1.000 total time=   0.8s
[CV 3/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 10/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.5s
[CV 6/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 2/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.7s
[CV 5/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 4/10; 10/15] END learning_rate=10, n_estimators=5;, score=1.000 total time=   0.7s
[CV 9/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.4s
[CV 1/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.7s
[CV 7/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.6s
[CV 1/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.4s
[CV 4/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.4s
[CV 4/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.6s
[CV 6/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.6s
[CV 4/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.6s
[CV 3/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.4s
[CV 8/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.6s
[CV 3/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 2/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.5s
[CV 8/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 9/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.4s
[CV 3/10; 11/15] END learning_rate=10, n_estimators=50;, score=1.000 total time=   0.7s
[CV 10/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.4s
[CV 10/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 7/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.5s
[CV 7/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 4/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 7/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.5s
[CV 1/10; 12/15] END learning_rate=10, n_estimators=250;, score=1.000 total time=   0.6s
[CV 5/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.5s
[CV 1/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 2/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 2/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 5/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 9/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.3s
[CV 3/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 10/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.3s
[CV 6/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.5s
[CV 8/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 8/10; 13/15] END learning_rate=100, n_estimators=5;, score=1.000 total time=   0.5s
[CV 6/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 5/10; 14/15] END learning_rate=100, n_estimators=50;, score=1.000 total time=   0.4s
[CV 4/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 8/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.2s
[CV 9/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.2s
[CV 6/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 1/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 7/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.3s
[CV 10/10; 15/15] END learning_rate=100, n_estimators=250;, score=1.000 total time=   0.2s
1.0 (+/-0.0) for {'learning_rate': 0.01, 'n_estimators': 5}
1.0 (+/-0.0) for {'learning_rate': 0.01, 'n_estimators': 50}
1.0 (+/-0.0) for {'learning_rate': 0.01, 'n_estimators': 250}
1.0 (+/-0.0) for {'learning_rate': 0.1, 'n_estimators': 5}
1.0 (+/-0.0) for {'learning_rate': 0.1, 'n_estimators': 50}
1.0 (+/-0.0) for {'learning_rate': 0.1, 'n_estimators': 250}
1.0 (+/-0.0) for {'learning_rate': 1, 'n_estimators': 5}
1.0 (+/-0.0) for {'learning_rate': 1, 'n_estimators': 50}
1.0 (+/-0.0) for {'learning_rate': 1, 'n_estimators': 250}
1.0 (+/-0.0) for {'learning_rate': 10, 'n_estimators': 5}
1.0 (+/-0.0) for {'learning_rate': 10, 'n_estimators': 50}
1.0 (+/-0.0) for {'learning_rate': 10, 'n_estimators': 250}
1.0 (+/-0.0) for {'learning_rate': 100, 'n_estimators': 5}
1.0 (+/-0.0) for {'learning_rate': 100, 'n_estimators': 50}
1.0 (+/-0.0) for {'learning_rate': 100, 'n_estimators': 250}
BEST PARAMS for AdaBoost + ACFM: {'learning_rate': 0.01, 'n_estimators': 5}

Train time for AdaBoost + ACFM: 0.028249998887379963 min

Training KNN for ACFM...
Fitting 10 folds for each of 36 candidates, totalling 360 fits
[CV 1/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
                                                                                                                                                                        [CV 2/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 4/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 5/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 6/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 7/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 8/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 9/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform..........
[CV 10/10; 1/36] START leaf_size=5, n_neighbors=5, p=1, weights=uniform.........
[CV 1/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 2/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 3/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 4/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 5/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 6/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 7/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 8/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 9/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance.........
[CV 10/10; 2/36] START leaf_size=5, n_neighbors=5, p=1, weights=distance........
[CV 1/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 2/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 3/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 4/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 5/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 6/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 7/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 8/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 9/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform..........
[CV 10/10; 3/36] START leaf_size=5, n_neighbors=5, p=2, weights=uniform.........
[CV 1/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 2/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 3/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 4/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 5/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 6/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 7/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 8/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 9/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance.........
[CV 10/10; 4/36] START leaf_size=5, n_neighbors=5, p=2, weights=distance........
[CV 1/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 2/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 3/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 4/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 5/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 6/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 7/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 8/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 9/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform.........
[CV 10/10; 5/36] START leaf_size=5, n_neighbors=50, p=1, weights=uniform........
[CV 1/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 2/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 3/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 4/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 5/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 6/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 3/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 7/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 4/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.1s
[CV 8/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 6/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.2s
[CV 9/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance........
[CV 2/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.2s
[CV 10/10; 6/36] START leaf_size=5, n_neighbors=50, p=1, weights=distance.......
[CV 10/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.2s
[CV 1/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 1/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.3s
[CV 2/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 9/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.3s
[CV 3/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 8/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.3s
[CV 4/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 8/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.4s
[CV 5/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 7/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.3s
[CV 6/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 2/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.4s
[CV 7/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 4/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.4s
[CV 8/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 7/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.5s
[CV 9/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform.........
[CV 9/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.4s
[CV 10/10; 7/36] START leaf_size=5, n_neighbors=50, p=2, weights=uniform........
[CV 1/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.4s
[CV 1/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 6/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.4s
[CV 2/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 5/10; 2/36] END leaf_size=5, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   2.5s
[CV 3/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 3/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.5s
[CV 4/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 4/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.4s
[CV 5/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 5/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.5s
[CV 6/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
                                                                                 [CV 2/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.4s
[CV 7/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 3/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.5s
[CV 8/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 10/10; 4/36] END leaf_size=5, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   2.6s
[CV 9/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance........
[CV 5/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.6s
[CV 10/10; 8/36] START leaf_size=5, n_neighbors=50, p=2, weights=distance.......
[CV 6/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.7s
[CV 1/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 1/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   2.8s
[CV 2/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 7/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 3/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 9/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 4/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 10/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 5/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 1/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.0s
[CV 6/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 8/10; 6/36] END leaf_size=5, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 7/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 2/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 7/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform........
[CV 4/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 9/36] START leaf_size=5, n_neighbors=250, p=1, weights=uniform.......
[CV 8/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 5/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 2/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 3/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 3/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 6/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 4/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 9/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 5/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 10/10; 8/36] END leaf_size=5, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 6/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 2/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 7/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 8/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   5.7s
[CV 8/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 3/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 9/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance......
[CV 5/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 10/36] START leaf_size=5, n_neighbors=250, p=1, weights=distance.....
[CV 1/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   5.9s
[CV 1/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 1/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 2/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 4/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 3/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 6/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 4/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 3/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   6.5s
[CV 5/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 6/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   6.8s
[CV 6/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 10/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   6.9s
[CV 7/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 7/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.0s
[CV 8/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 5/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.0s
[CV 9/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform.......
[CV 8/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 11/36] START leaf_size=5, n_neighbors=250, p=2, weights=uniform......
[CV 7/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   2.0s
[CV 1/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 10/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 3/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.6s
[CV 3/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 9/10; 10/36] END leaf_size=5, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 4/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 4/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 5/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 10/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.8s
[CV 6/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 4/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.1s
[CV 7/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 9/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.3s
[CV 8/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 6/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.3s
[CV 9/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance......
[CV 5/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 10/10; 12/36] START leaf_size=5, n_neighbors=250, p=2, weights=distance.....
[CV 2/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 1/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 4/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.6s
[CV 2/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 8/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.8s
[CV 3/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 2/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.8s
[CV 4/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 7/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.9s
[CV 5/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 5/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.8s
[CV 6/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 1/10; 1/36] END leaf_size=5, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   9.0s
[CV 7/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 3/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 8/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 9/10; 3/36] END leaf_size=5, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   9.1s
[CV 9/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform........
[CV 4/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 13/36] START leaf_size=50, n_neighbors=5, p=1, weights=uniform.......
[CV 1/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 1/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 1/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.1s
[CV 2/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 3/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.2s
[CV 3/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 2/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 4/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 7/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.3s
[CV 5/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 2/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.4s
[CV 6/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 5/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 7/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 7/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 8/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 9/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.5s
[CV 9/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance.......
[CV 6/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.6s
[CV 10/10; 14/36] START leaf_size=50, n_neighbors=5, p=1, weights=distance......
[CV 6/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   2.0s
[CV 1/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 9/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 10/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 3/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 10/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   9.8s
[CV 4/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 4/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 5/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 8/10; 5/36] END leaf_size=5, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=  10.0s
[CV 6/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 8/10; 12/36] END leaf_size=5, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 7/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 2/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.2s
[CV 8/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 10/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 9/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform........
[CV 5/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.1s
[CV 10/10; 15/36] START leaf_size=50, n_neighbors=5, p=2, weights=uniform.......
[CV 1/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.4s
[CV 1/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 7/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.2s
[CV 2/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 4/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 3/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 1/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 4/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 9/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.3s
[CV 5/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 3/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 6/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 3/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.6s
[CV 7/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 7/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 10/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance.......
[CV 8/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 16/36] START leaf_size=50, n_neighbors=5, p=2, weights=distance......
[CV 9/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 6/10; 14/36] END leaf_size=50, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 2/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 2/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   9.1s
[CV 3/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 6/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   9.0s
[CV 4/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 5/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   9.1s
[CV 5/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 2/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 6/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 8/10; 7/36] END leaf_size=5, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   9.5s
[CV 7/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 4/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.2s
[CV 8/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 3/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform.......
[CV 1/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 10/10; 17/36] START leaf_size=50, n_neighbors=50, p=1, weights=uniform......
[CV 8/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.2s
[CV 1/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 6/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 2/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 5/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 3/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 9/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.2s
[CV 4/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 7/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 5/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 10/10; 16/36] END leaf_size=50, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 6/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 2/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.4s
[CV 7/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 4/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 2/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 9/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance......
[CV 10/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   9.5s
[CV 10/10; 18/36] START leaf_size=50, n_neighbors=50, p=1, weights=distance.....
[CV 1/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 3/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 4/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.4s
[CV 3/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 5/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 4/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 1/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.4s
[CV 5/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 6/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.9s
[CV 6/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 7/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.9s
[CV 7/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 6/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 8/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 3/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.4s
[CV 9/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform.......
[CV 7/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 10/10; 19/36] START leaf_size=50, n_neighbors=50, p=2, weights=uniform......
[CV 5/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.5s
[CV 1/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 8/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.3s
[CV 2/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 10/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 3/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 8/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 4/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 9/10; 18/36] END leaf_size=50, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 5/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 9/10; 9/36] END leaf_size=5, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.5s
[CV 6/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 1/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.1s
[CV 7/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 3/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   9.6s
[CV 8/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 2/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.4s
[CV 9/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance......
[CV 8/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.1s
[CV 10/10; 20/36] START leaf_size=50, n_neighbors=50, p=2, weights=distance.....
[CV 4/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.4s
[CV 1/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 3/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.6s
[CV 2/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 10/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.2s
[CV 3/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 5/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.5s
[CV 4/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 1/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 5/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 6/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.6s
[CV 6/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 1/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.6s
[CV 7/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 1/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   6.7s
[CV 8/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 7/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.7s
[CV 9/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform......
[CV 3/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 10/10; 21/36] START leaf_size=50, n_neighbors=250, p=1, weights=uniform.....
[CV 4/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 1/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 4/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.8s
[CV 2/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 5/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 3/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 8/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 4/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 2/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  11.1s
[CV 5/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 2/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   2.1s
[CV 6/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 2/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.3s
[CV 7/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 9/10; 13/36] END leaf_size=50, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.1s
[CV 8/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 3/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.3s
[CV 9/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance.....
[CV 9/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.2s
[CV 10/10; 22/36] START leaf_size=50, n_neighbors=250, p=1, weights=distance....
[CV 6/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.6s
[CV 1/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 9/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.3s
[CV 2/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 5/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.4s
[CV 3/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 6/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   2.1s
[CV 4/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 7/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 5/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 7/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.6s
[CV 6/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 10/10; 20/36] END leaf_size=50, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 7/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 5/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  11.1s
[CV 8/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 6/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 9/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform......
[CV 4/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.9s
[CV 10/10; 23/36] START leaf_size=50, n_neighbors=250, p=2, weights=uniform.....
[CV 8/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.9s
[CV 1/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 7/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.8s
[CV 2/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 10/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 3/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 8/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 4/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 9/10; 15/36] END leaf_size=50, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 5/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 2/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 6/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 5/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 7/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 4/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 8/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 8/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 9/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance.....
[CV 1/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 10/10; 24/36] START leaf_size=50, n_neighbors=250, p=2, weights=distance....
[CV 7/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 1/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 10/10; 11/36] END leaf_size=5, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  11.6s
[CV 2/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 3/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 3/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 2/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.8s
[CV 4/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 9/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 5/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 4/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.6s
[CV 6/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 10/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 7/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 6/10; 22/36] END leaf_size=50, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   2.0s
[CV 8/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 2/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform.......
[CV 6/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.5s
[CV 10/10; 25/36] START leaf_size=250, n_neighbors=5, p=1, weights=uniform......
[CV 3/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.0s
[CV 1/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 7/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.5s
[CV 2/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 5/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.1s
[CV 3/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 1/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 4/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 1/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 5/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 4/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.2s
[CV 6/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 3/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 7/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 9/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 10/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance......
[CV 7/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 10/10; 26/36] START leaf_size=250, n_neighbors=5, p=1, weights=distance.....
[CV 8/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 1/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 5/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 2/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 9/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.3s
[CV 3/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 6/10; 24/36] END leaf_size=50, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 4/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 10/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 5/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 8/10; 17/36] END leaf_size=50, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.7s
[CV 6/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 3/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.1s
[CV 7/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 2/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.0s
[CV 8/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 2/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 9/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform.......
[CV 5/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.1s
[CV 10/10; 27/36] START leaf_size=250, n_neighbors=5, p=2, weights=uniform......
[CV 1/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 4/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 2/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 3/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.2s
[CV 3/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 6/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 4/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 7/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 5/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 8/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 6/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 9/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 7/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 10/10; 26/36] END leaf_size=250, n_neighbors=5, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 8/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 5/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.5s
[CV 9/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance......
[CV 1/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.4s
[CV 10/10; 28/36] START leaf_size=250, n_neighbors=5, p=2, weights=distance.....
[CV 4/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 1/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 1/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 6/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 3/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 2/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 4/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 4/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 5/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 8/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.3s
[CV 6/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 3/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 7/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 9/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 8/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 6/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 9/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform......
[CV 7/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.4s
[CV 10/10; 29/36] START leaf_size=250, n_neighbors=50, p=1, weights=uniform.....
[CV 7/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 5/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 2/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 8/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 3/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 9/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 4/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 10/10; 28/36] END leaf_size=250, n_neighbors=5, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 5/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 10/10; 19/36] END leaf_size=50, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   8.8s
[CV 6/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 2/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.2s
[CV 7/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 1/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 8/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 3/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 9/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance.....
[CV 5/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 10/10; 30/36] START leaf_size=250, n_neighbors=50, p=1, weights=distance....
[CV 4/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 1/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 6/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 2/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 8/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.3s
[CV 3/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 7/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.6s
[CV 4/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 6/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.0s
[CV 5/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 7/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.0s
[CV 6/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 1/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.5s
[CV 7/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 3/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.4s
[CV 8/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 9/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 9/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform......
[CV 3/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.2s
[CV 10/10; 31/36] START leaf_size=250, n_neighbors=50, p=2, weights=uniform.....
[CV 8/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.5s
[CV 1/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 9/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.3s
[CV 2/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 10/10; 30/36] END leaf_size=250, n_neighbors=50, p=1, weights=distance;, score=1.000 total time=   1.5s
[CV 3/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 10/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.4s
[CV 4/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 5/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.3s
[CV 5/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 4/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   7.9s
[CV 6/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 1/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.8s
[CV 7/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 5/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.1s
[CV 8/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 8/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.5s
[CV 9/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance.....
[CV 4/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.7s
[CV 10/10; 32/36] START leaf_size=250, n_neighbors=50, p=2, weights=distance....
[CV 7/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.7s
[CV 1/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 2/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.0s
[CV 2/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 2/10; 25/36] END leaf_size=250, n_neighbors=5, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 3/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 5/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   6.8s
[CV 4/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 6/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.9s
[CV 5/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 2/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.1s
[CV 6/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 7/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   6.8s
[CV 7/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 1/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.1s
[CV 8/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 4/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.0s
[CV 9/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform.....
[CV 10/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  10.9s
[CV 10/10; 33/36] START leaf_size=250, n_neighbors=250, p=1, weights=uniform....
[CV 1/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.6s
[CV 1/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 4/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.1s
[CV 2/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 8/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.2s
[CV 3/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 9/10; 21/36] END leaf_size=50, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=  11.3s
[CV 4/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 3/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 5/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 3/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 6/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 2/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 7/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 6/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 2/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.8s
[CV 9/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance....
[CV 3/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.8s
[CV 10/10; 34/36] START leaf_size=250, n_neighbors=250, p=1, weights=distance...
[CV 5/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 1/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 10/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.3s
[CV 2/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 1/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 3/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 10/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.5s
[CV 4/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 7/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.7s
[CV 5/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 4/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   8.1s
[CV 6/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 6/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.8s
[CV 7/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 7/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 8/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 9/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.7s
[CV 9/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform.....
[CV 8/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.4s
[CV 10/10; 35/36] START leaf_size=250, n_neighbors=250, p=2, weights=uniform....
[CV 6/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.9s
[CV 1/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 9/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  10.7s
[CV 2/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 8/10; 27/36] END leaf_size=250, n_neighbors=5, p=2, weights=uniform;, score=1.000 total time=   7.9s
[CV 3/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 9/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 4/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 10/10; 32/36] END leaf_size=250, n_neighbors=50, p=2, weights=distance;, score=1.000 total time=   1.8s
[CV 5/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 1/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.4s
[CV 6/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 3/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   6.6s
[CV 7/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 5/10; 23/36] END leaf_size=50, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=  11.7s
[CV 8/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 2/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.7s
[CV 9/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance....
[CV 3/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 10/10; 36/36] START leaf_size=250, n_neighbors=250, p=2, weights=distance...
[CV 7/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 9/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 10/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.8s
[CV 8/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   1.9s
[CV 4/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   2.1s
[CV 6/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   2.0s
[CV 5/10; 34/36] END leaf_size=250, n_neighbors=250, p=1, weights=distance;, score=1.000 total time=   2.1s
[CV 4/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 3/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.6s
[CV 1/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.9s
[CV 5/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 8/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.6s
[CV 5/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.7s
[CV 1/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.4s
[CV 7/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   7.8s
[CV 6/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.5s
[CV 2/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.4s
[CV 4/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.1s
[CV 6/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.0s
[CV 7/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 9/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.3s
[CV 8/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 10/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.2s
[CV 10/10; 36/36] END leaf_size=250, n_neighbors=250, p=2, weights=distance;, score=1.000 total time=   1.7s
[CV 9/10; 29/36] END leaf_size=250, n_neighbors=50, p=1, weights=uniform;, score=1.000 total time=   8.5s
[CV 1/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.8s
[CV 2/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.0s
[CV 10/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   5.8s
[CV 7/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.3s
[CV 8/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.5s
[CV 5/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.9s
[CV 9/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.4s
[CV 6/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   6.8s
[CV 4/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.0s
[CV 3/10; 31/36] END leaf_size=250, n_neighbors=50, p=2, weights=uniform;, score=1.000 total time=   7.1s
[CV 10/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.4s
[CV 1/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.9s
[CV 2/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.9s
[CV 8/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   5.7s
[CV 4/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.9s
[CV 6/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.8s
[CV 8/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.8s
[CV 3/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   7.0s
[CV 9/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.8s
[CV 4/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.0s
[CV 6/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   5.9s
[CV 7/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   6.8s
[CV 5/10; 33/36] END leaf_size=250, n_neighbors=250, p=1, weights=uniform;, score=1.000 total time=   7.0s
[CV 3/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.0s
[CV 1/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.1s
[CV 10/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   5.9s
[CV 9/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   5.9s
[CV 5/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.0s
[CV 7/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.0s
[CV 2/10; 35/36] END leaf_size=250, n_neighbors=250, p=2, weights=uniform;, score=1.000 total time=   6.1s
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 50, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 50, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 50, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 50, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 250, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 250, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 250, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 5, 'n_neighbors': 250, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 50, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 50, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 50, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 50, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 250, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 250, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 250, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 50, 'n_neighbors': 250, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 50, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 50, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 50, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 50, 'p': 2, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 250, 'p': 1, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 250, 'p': 1, 'weights': 'distance'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 250, 'p': 2, 'weights': 'uniform'}
1.0 (+/-0.0) for {'leaf_size': 250, 'n_neighbors': 250, 'p': 2, 'weights': 'distance'}
BEST PARAMS for KNN + ACFM: {'leaf_size': 5, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}

Train time for KNN + ACFM: 0.5751962900161743 min

Training Decision Tree for ACFM...
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV 1/10; 1/6] START criterion=gini, splitter=best..............................
[CV 2/10; 1/6] START criterion=gini, splitter=best..............................
[CV 3/10; 1/6] START criterion=gini, splitter=best..............................
[CV 4/10; 1/6] START criterion=gini, splitter=best..............................
[CV 5/10; 1/6] START criterion=gini, splitter=best..............................
[CV 6/10; 1/6] START criterion=gini, splitter=best..............................
[CV 7/10; 1/6] START criterion=gini, splitter=best..............................
[CV 8/10; 1/6] START criterion=gini, splitter=best..............................
[CV 9/10; 1/6] START criterion=gini, splitter=best..............................
[CV 10/10; 1/6] START criterion=gini, splitter=best.............................
[CV 1/10; 2/6] START criterion=gini, splitter=random............................
[CV 2/10; 2/6] START criterion=gini, splitter=random............................
[CV 3/10; 2/6] START criterion=gini, splitter=random............................
[CV 4/10; 2/6] START criterion=gini, splitter=random............................
[CV 5/10; 2/6] START criterion=gini, splitter=random............................
[CV 6/10; 2/6] START criterion=gini, splitter=random............................
[CV 7/10; 2/6] START criterion=gini, splitter=random............................
[CV 8/10; 2/6] START criterion=gini, splitter=random............................
[CV 9/10; 2/6] START criterion=gini, splitter=random............................
[CV 10/10; 2/6] START criterion=gini, splitter=random...........................
[CV 1/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 2/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 3/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 4/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 5/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 6/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 7/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 8/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 9/10; 3/6] START criterion=entropy, splitter=best...........................
[CV 10/10; 3/6] START criterion=entropy, splitter=best..........................
[CV 1/10; 4/6] START criterion=entropy, splitter=random.........................
[CV 4/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.4s
[CV 2/10; 4/6] START criterion=entropy, splitter=random.........................
[CV 3/10; 4/6] START criterion=entropy, splitter=random.........................
[CV 4/10; 4/6] START criterion=entropy, splitter=random.........................
[CV 5/10; 4/6] START criterion=entropy, splitter=random.........................
[CV 5/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.4s
[CV 3/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 1/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.4s
[CV 4/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 2/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.4s
[CV 5/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 8/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.4s
[CV 6/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 2/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.4s
[CV 7/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 8/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 1/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.4s
[CV 9/10; 5/6] START criterion=log_loss, splitter=best..........................
[CV 4/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.4s
[CV 10/10; 5/6] START criterion=log_loss, splitter=best.........................
[CV 7/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.4s
[CV 1/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 9/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.4s
[CV 2/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 3/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 4/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 3/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.5s
[CV 5/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 6/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 7/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 8/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 5/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.5s
[CV 9/10; 6/6] START criterion=log_loss, splitter=random........................
[CV 7/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.5s
[CV 10/10; 6/6] START criterion=log_loss, splitter=random.......................
[CV 10/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.5s
[CV 10/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.2s
[CV 3/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.2s
[CV 8/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.5s
[CV 1/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.5s
[CV 8/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.2s
[CV 5/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 2/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 2/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.5s
[CV 10/10; 1/6] END criterion=gini, splitter=best;, score=1.000 total time=   0.6s
[CV 5/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.3s
[CV 6/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.2s
[CV 6/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 7/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 8/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.1s
[CV 9/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.2s
[CV 8/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 5/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 6/10; 2/6] END criterion=gini, splitter=random;, score=1.000 total time=   0.6s
[CV 3/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 6/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 4/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.3s
[CV 7/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 7/10; 3/6] END criterion=entropy, splitter=best;, score=1.000 total time=   0.3s
[CV 2/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 9/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 4/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 1/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 4/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 9/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 4/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.1s
[CV 3/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 9/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.1s
[CV 1/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.3s
[CV 10/10; 4/6] END criterion=entropy, splitter=random;, score=1.000 total time=   0.2s
[CV 2/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.2s
[CV 1/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.2s
[CV 7/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.1s
[CV 10/10; 5/6] END criterion=log_loss, splitter=best;, score=1.000 total time=   0.2s
[CV 3/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.2s
[CV 5/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.2s
[CV 8/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.1s
[CV 10/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.1s
[CV 6/10; 6/6] END criterion=log_loss, splitter=random;, score=1.000 total time=   0.2s
1.0 (+/-0.0) for {'criterion': 'gini', 'splitter': 'best'}
1.0 (+/-0.0) for {'criterion': 'gini', 'splitter': 'random'}
1.0 (+/-0.0) for {'criterion': 'entropy', 'splitter': 'best'}
1.0 (+/-0.0) for {'criterion': 'entropy', 'splitter': 'random'}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'splitter': 'best'}
1.0 (+/-0.0) for {'criterion': 'log_loss', 'splitter': 'random'}
BEST PARAMS for DT + ACFM: {'criterion': 'gini', 'splitter': 'best'}

Train time for DT + ACFM: 0.012314355373382569 min

Training Naive Bayes for ACFM...
None





ERROR in training of NB





Training XGB for ACFM...
None





ERROR in training of XGB





Training LR for ACFM...
None





ERROR in training of LR





Training KM for ACFM...
Fitting 10 folds for each of 2430 candidates, totalling 24300 fits
[CV 1/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 2/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
e@      r@     w@     w@     0w@     0w@     n@     }@      o@     @i@     @i@     Y@     `@      A@     @Z@     Y@     H@      o@      o@     o@     @^@     @i@     0r@     @i@     @i@     0r@     @i@     c@     @i@      r@     0w@     @i@      B@     @d@     [@     @Z@     @     @     M@     O@     M@     @     U@     O@     O@     K@     L@     @     O@     O@     @     @     O@     @     @     
@     }@     @     @     O@     O@     @     @     @     @     @     @     @     @     @     @     @     @     @     @     O@     @     O@     O@     @     @     O@     O@     @     @     @     (@     (@     (@     P}@     (@     (@     (@      p@      p@      p@     (@     @     (@     P}@      \@      \@  [CV 3/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 5/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 6/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 7/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 8/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 9/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 1/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 1/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 2/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 3/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 4/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 5/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 6/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 7/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 8/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 9/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 10/10; 2/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 1/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 2/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 3/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 4/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 5/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 6/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 7/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 8/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 9/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 10/10; 3/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 1/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 2/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 4/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 5/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 6/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 7/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 10/10; 4/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 2/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 3/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 4/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 5/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 6/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 7/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 8/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 9/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 10/10; 5/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 1/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 2/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 3/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 4/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 5/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 6/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 7/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   3.9s
[CV 7/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 2/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-3211353460285.228 total time=   3.6s
[CV 8/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 9/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   4.4s
[CV 9/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 6/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-263311323007.202 total time=   3.1s
[CV 10/10; 6/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 2/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-3211353460285.229 total time=   4.6s
[CV 1/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 9/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-37656997227.169 total time=   4.0s
                                                                                                                         [CV 2/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-286483395630.548 total time=   4.5s
[CV 3/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 2/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-3211353460285.229 total time=   4.6s
[CV 4/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-263311323007.202 total time=   4.2s
[CV 5/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-286483395630.548 total time=   3.7s
[CV 6/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-286483395630.548 total time=   2.3s
[CV 7/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   4.7s
[CV 8/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 7/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   4.7s
[CV 9/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   4.8s
[CV 10/10; 7/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-286483395630.548 total time=   1.8s
[CV 1/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 4/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   4.8s
[CV 2/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 8/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-930470450607.652 total time=   3.0s
[CV 3/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 7/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-2045579971968.060 total time=   2.6s
[CV 4/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 6/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-263311323007.202 total time=   2.3s
[CV 5/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 4/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-136182744001.230 total time=   3.6s
[CV 6/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 5/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-3186185568868.183 total time=   4.4s
[CV 7/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 8/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-930470450607.652 total time=   4.2s
[CV 8/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 10/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-380930465110.889 total time=   4.0s
[CV 9/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 3/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-286483395630.548 total time=   4.9s
[CV 10/10; 8/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 8/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-930470450607.652 total time=   4.9s
[CV 1/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 10/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-380930465110.889 total time=   3.0s
[CV 2/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 1/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-2309281712602.756 total time=   3.0s
[CV 3/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 4/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-136182744001.230 total time=   4.7s
[CV 4/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 5/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-3186185568868.183 total time=   4.9s
[CV 5/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 2/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-3211353460285.228 total time=   2.0s
[CV 6/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 5/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-3186185568868.184 total time=   2.8s
[CV 7/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 2/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-3211353460285.229 total time=   2.9s
[CV 8/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 2/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-3211353460285.228 total time=   2.5s
[CV 9/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 10/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-380930465110.889 total time=   2.6s
[CV 10/10; 9/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 3/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   2.9s
[CV 1/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 6/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-263311323007.202 total time=   1.6s
[CV 2/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 9/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   2.7s
[CV 3/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-3186185568868.183 total time=   1.9s
[CV 4/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-3186185568868.183 total time=   2.5s
[CV 5/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   3.5s
[CV 6/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-136182744001.230 total time=   2.1s
[CV 7/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-3186185568868.183 total time=   3.6s
[CV 8/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   2.9s
[CV 9/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 8/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-930470450607.652 total time=   2.4s
[CV 10/10; 10/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   2.5s
[CV 1/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 9/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-37656997227.169 total time=   3.2s
[CV 2/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 6/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   2.9s
[CV 3/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 1/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-2309281712602.756 total time=   2.7s
[CV 4/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 9/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-37656997227.169 total time=   2.3s
[CV 5/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 10/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-380930465110.890 total time=   2.3s
[CV 6/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 8/10; 4/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   2.9s
[CV 7/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 1/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-2309281712602.756 total time=   2.3s
[CV 8/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 4/10; 5/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-136182744001.230 total time=   2.7s
[CV 9/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 1/10; 2/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-2309293131268.707 total time=   5.2s
[CV 10/10; 11/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 1/10; 3/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-2309293131268.707 total time=   4.4s
[CV 1/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 1/10; 1/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-2309293131268.707 total time=   5.3s
[CV 2/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 10/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-380930465110.889 total time=   1.3s
[CV 3/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 9/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-37656997227.169 total time=   1.5s
[CV 4/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 8/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-930470450607.652 total time=   1.6s
[CV 5/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 7/10; 6/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-2045579971968.060 total time=   1.7s
[CV 6/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 8/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   1.4s
[CV 7/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 4/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   1.5s
[CV 8/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 10/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   1.5s
[CV 9/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 5/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-3186185568868.183 total time=   1.6s
[CV 10/10; 12/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 8/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-930470450607.652 total time=   1.5s
[CV 1/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 1/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-2309281712602.756 total time=   1.8s
[CV 2/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   1.7s
[CV 3/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 9/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   1.6s
[CV 4/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-3211353460285.228 total time=   1.6s
[CV 5/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   1.6s
[CV 6/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 6/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-263311323007.202 total time=   1.6s
[CV 7/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 7/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   1.6s
[CV 8/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-380930465110.889 total time=   1.6s
[CV 9/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-286483395630.548 total time=   1.6s
[CV 10/10; 13/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 4/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-136182744001.230 total time=   1.6s
[CV 1/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 2/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-3211353460285.229 total time=   1.9s
[CV 2/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 10/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-380930465110.889 total time=   1.6s
[CV 3/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 1/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-2309281712602.755 total time=   1.7s
[CV 4/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 6/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   1.9s
[CV 5/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 5/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-3186185568868.183 total time=   1.8s
[CV 6/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 4/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-136182744001.230 total time=   1.8s
[CV 7/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 5/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   1.7s
[CV 8/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 9/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-37656997227.169 total time=   1.7s
[CV 9/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 3/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-286483395630.548 total time=   1.9s
[CV 10/10; 14/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 1/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-2309281712602.756 total time=   1.9s
[CV 1/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 9/10; 8/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-37656997227.169 total time=   1.9s
[CV 2/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 6/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-263311323007.202 total time=   1.9s
[CV 3/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 7/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   2.0s
[CV 4/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 7/10; 7/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   2.2s
[CV 5/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 8/10; 9/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-930470450607.652 total time=   2.0s
[CV 6/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 2/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-3211353460285.229 total time=   2.7s
[CV 7/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 8/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-930470450607.652 total time=   2.7s
[CV 8/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 7/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   2.8s
[CV 9/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 6/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   2.9s
[CV 10/10; 15/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 9/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   3.0s
[CV 1/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-3186185568868.182 total time=   3.0s
[CV 2/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 3/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-286483395630.549 total time=   3.1s
[CV 3/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 10/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   3.1s
[CV 4/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 1/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-2309281712602.756 total time=   3.1s
[CV 5/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 8/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-930470450607.652 total time=   3.1s
[CV 6/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-3211353460285.229 total time=   2.9s
[CV 7/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 4/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   3.2s
[CV 8/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 1/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-2309281712602.756 total time=   3.3s
[CV 9/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-3211353460285.229 total time=   3.4s
[CV 10/10; 16/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 10/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-3186185568868.183 total time=   3.3s
[CV 1/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 3/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-286483395630.548 total time=   3.3s
[CV 2/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 6/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-263311323007.202 total time=   3.2s
[CV 3/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 9/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-37656997227.169 total time=   3.2s
[CV 4/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 7/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   3.4s
[CV 5/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 10/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-380930465110.889 total time=   3.3s
[CV 6/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 1/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-2309281712602.755 total time=   3.4s
[CV 7/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 4/10; 11/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-136182744001.230 total time=   3.6s
[CV 8/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 5/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-3186185568868.183 total time=   2.9s
[CV 9/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 4/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   2.7s
[CV 10/10; 17/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 1/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-2309281712602.756 total time=   2.8s
[CV 1/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 3/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-286483395630.548 total time=   3.2s
[CV 2/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 2/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-3211353460285.228 total time=   2.9s
[CV 3/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 4/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-136182744001.230 total time=   2.7s
[CV 4/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 8/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-930470450607.652 total time=   3.1s
[CV 5/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 6/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-263311323007.202 total time=   3.2s
[CV 6/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 9/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-37656997227.169 total time=   3.1s
[CV 7/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 4/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-136182744001.230 total time=   3.4s
[CV 8/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 8/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   3.0s
[CV 9/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 10/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-380930465110.889 total time=   2.9s
[CV 10/10; 18/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 1/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-2309281712602.755 total time=   2.9s
[CV 1/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 9/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   3.0s
[CV 2/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 5/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-3186185568868.184 total time=   2.9s
[CV 3/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 10/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-380930465110.889 total time=   3.2s
[CV 4/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 2/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-3211353460285.228 total time=   3.0s
[CV 5/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-263311323007.202 total time=   2.6s
[CV 6/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 7/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-2045579971968.060 total time=   3.1s
[CV 7/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 7/10; 12/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   3.4s
[CV 8/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 5/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-3186185568868.182 total time=   3.2s
[CV 9/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 3/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   3.2s
[CV 10/10; 19/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-136182744001.230 total time=   2.7s
[CV 1/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 10/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-380930465110.889 total time=   2.9s
[CV 2/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 6/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-263311323007.202 total time=   3.1s
[CV 3/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 3/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-286483395630.549 total time=   3.1s
[CV 4/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 6/10; 13/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   3.3s
[CV 5/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 9/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-37656997227.169 total time=   3.2s
[CV 6/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 2/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-3211353460285.229 total time=   3.1s
[CV 7/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 5/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-3186185568868.182 total time=   3.0s
[CV 8/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 7/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   3.3s
[CV 9/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 8/10; 14/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-930470450607.652 total time=   3.3s
[CV 10/10; 20/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 1/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-2309281712602.756 total time=   3.2s
[CV 1/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 3/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-286483395630.548 total time=   3.3s
[CV 2/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 7/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-2045579971968.060 total time=   2.8s
[CV 3/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 10/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-380930465110.889 total time=   2.8s
[CV 4/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 8/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-930470450607.652 total time=   2.9s
[CV 5/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 9/10; 15/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-37656997227.169 total time=   3.0s
[CV 6/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 1/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-2309281712602.755 total time=   2.8s
[CV 7/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 4/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   2.8s
[CV 8/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 5/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-3186185568868.184 total time=   2.9s
[CV 9/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 10/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   2.8s
[CV 10/10; 21/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 2/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-3211353460285.229 total time=   3.0s
[CV 1/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 8/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   2.9s
[CV 2/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 3/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   3.0s
[CV 3/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 6/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   3.0s
[CV 4/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   3.0s
[CV 5/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 16/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   3.1s
[CV 6/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 2/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-3211353460285.229 total time=   3.1s
[CV 7/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 3/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-286483395630.549 total time=   3.1s
[CV 8/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 6/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-263311323007.202 total time=   2.9s
[CV 9/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   3.0s
[CV 10/10; 22/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 4/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-136182744001.230 total time=   3.3s
[CV 1/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 1/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-2309281712602.755 total time=   3.3s
[CV 2/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 9/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-37656997227.169 total time=   2.8s
[CV 3/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 5/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-3186185568868.182 total time=   3.3s
[CV 4/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 8/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-930470450607.652 total time=   3.2s
[CV 5/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 7/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   2.8s
[CV 6/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 2/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   3.0s
[CV 7/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 10/10; 17/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-380930465110.889 total time=   3.1s
[CV 8/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 4/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-136182744001.230 total time=   2.9s
[CV 9/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 9/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-37656997227.169 total time=   2.8s
[CV 10/10; 23/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 6/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-263311323007.202 total time=   2.9s
[CV 1/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 10/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-380930465110.889 total time=   2.9s
[CV 3/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 5/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   3.0s
[CV 4/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 3/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-286483395630.549 total time=   3.1s
[CV 5/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 1/10; 18/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-2309281712602.755 total time=   3.6s
[CV 6/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 10/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   4.1s
[CV 7/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 7/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   4.1s
[CV 8/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 8/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-930470450607.652 total time=   4.1s
[CV 9/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 9/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   4.2s
[CV 10/10; 24/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 2/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-3211353460285.229 total time=   4.2s
[CV 1/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 2/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-3211353460285.229 total time=   4.3s
[CV 2/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 9/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-37656997227.169 total time=   4.0s
[CV 3/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 8/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-930470450607.652 total time=   4.1s
[CV 4/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 3/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-286483395630.548 total time=   4.4s
[CV 5/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 5/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-3186185568868.183 total time=   4.5s
[CV 6/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 1/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-2309281712602.755 total time=   4.6s
[CV 7/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-136182744001.230 total time=   4.4s
[CV 8/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   4.6s
[CV 9/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 3/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-286483395630.548 total time=   4.7s
[CV 10/10; 25/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 5/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-3186185568868.183 total time=   4.5s
[CV 1/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 2/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-3211353460285.229 total time=   4.1s
[CV 2/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 7/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   4.4s
[CV 3/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 10/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-380930465110.889 total time=   4.4s
[CV 4/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 6/10; 19/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   4.8s
[CV 5/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 6/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-263311323007.202 total time=   4.6s
[CV 6/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 1/10; 20/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-2309281712602.756 total time=   4.8s
[CV 7/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 1/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-2309281712602.756 total time=   4.6s
[CV 8/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 8/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-930470450607.652 total time=   4.1s
                                                                                                                                                                                                                                                                                                [CV 9/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 6/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-263311323007.202 total time=   4.3s
[CV 10/10; 26/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 5/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-3186185568868.182 total time=   4.6s
[CV 1/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 7/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-2045579971968.060 total time=   3.9s
[CV 2/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 3/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-286483395630.549 total time=   4.9s
[CV 3/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 2/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-3211353460285.229 total time=   4.3s
[CV 4/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 9/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-37656997227.169 total time=   4.4s
[CV 5/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 10/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-380930465110.889 total time=   4.4s
[CV 6/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 1/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-2309281712602.755 total time=   4.4s
[CV 7/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 7/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   4.7s
[CV 8/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 6/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   4.2s
[CV 9/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 3/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   4.4s
[CV 10/10; 27/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 9/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   4.1s
[CV 1/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 21/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-136182744001.230 total time=   4.9s
[CV 2/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   4.4s
[CV 3/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-286483395630.548 total time=   4.0s
[CV 4/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 5/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-3186185568868.183 total time=   4.5s
[CV 5/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 8/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   4.4s
[CV 6/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 2/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-3211353460285.229 total time=   4.3s
[CV 7/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-136182744001.230 total time=   4.3s
[CV 8/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 22/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-380930465110.889 total time=   4.5s
[CV 9/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-136182744001.230 total time=   3.8s
[CV 10/10; 28/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 7/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   4.1s
[CV 1/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 1/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-2309281712602.755 total time=   4.6s
[CV 2/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 10/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-380930465110.889 total time=   4.1s
[CV 3/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 5/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-3186185568868.183 total time=   4.4s
[CV 4/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 6/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-263311323007.202 total time=   4.3s
[CV 5/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 8/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-930470450607.652 total time=   4.4s
[CV 6/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 2/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-3211353460285.228 total time=   4.4s
[CV 7/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 6/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-263311323007.202 total time=   4.0s
[CV 8/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 9/10; 23/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-37656997227.169 total time=   4.5s
[CV 9/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 5/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-3186185568868.183 total time=   4.5s
[CV 10/10; 29/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 3/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-286483395630.548 total time=   4.5s
[CV 1/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 1/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-2309281712602.755 total time=   4.6s
[CV 2/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 1/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-2309219000441.922 total time=   2.0s
[CV 3/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 2/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-3211330942553.760 total time=   2.0s
[CV 4/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 3/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-286422373961.935 total time=   2.0s
[CV 5/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 10/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-380930465110.889 total time=   3.9s
[CV 6/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 5/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-3186125016341.296 total time=   1.9s
[CV 7/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 6/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-263247792386.199 total time=   1.9s
[CV 8/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 7/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-2045518893039.481 total time=   1.9s
[CV 9/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 9/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-37656997227.169 total time=   4.2s
[CV 10/10; 30/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 4/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-136118931994.890 total time=   2.2s
[CV 1/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-930543882795.614 total time=   2.0s
[CV 2/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 4/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-136118931994.890 total time=   1.7s
[CV 3/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-930470450607.652 total time=   4.4s
[CV 4/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-37594468474.076 total time=   2.1s
[CV 5/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 2/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-3211330942553.761 total time=   1.9s
[CV 6/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-2309219000441.921 total time=   2.0s
[CV 7/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 7/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   4.2s
[CV 8/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-286422373961.935 total time=   2.0s
[CV 9/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 10/10; 28/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-380870744559.434 total time=   2.2s
[CV 10/10; 31/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-2309281712602.756 total time=   4.5s
[CV 1/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 7/10; 24/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-2045579971968.060 total time=   4.7s
[CV 2/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 7/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-2045518893039.481 total time=   1.8s
[CV 3/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 6/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   4.4s
[CV 4/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 5/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-3186125016341.297 total time=   2.0s
[CV 5/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 4/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-136182744001.230 total time=   4.2s
[CV 6/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 6/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-263247792386.199 total time=   2.0s
[CV 7/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 2/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-3211353460285.229 total time=   4.8s
[CV 8/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 9/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-37594468474.076 total time=   1.9s
[CV 9/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 4/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   4.6s
[CV 10/10; 32/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 2/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-3211330942553.760 total time=   1.8s
[CV 1/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 1/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-2309219000441.921 total time=   1.8s
[CV 2/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 8/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   4.6s
[CV 3/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 9/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   4.5s
[CV 4/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 10/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   4.6s
[CV 5/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 1/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-2309281712602.755 total time=   4.5s
[CV 6/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 3/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   4.9s
[CV 7/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 5/10; 25/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-3186185568868.183 total time=   4.8s
[CV 8/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 10/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-380870744559.434 total time=   2.1s
[CV 9/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 6/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-263311323007.202 total time=   4.5s
[CV 10/10; 33/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 8/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-930470450607.652 total time=   4.4s
[CV 1/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 8/10; 29/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-930543882795.614 total time=   2.2s
[CV 2/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 5/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-3186185568868.183 total time=   4.6s
[CV 3/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 7/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   4.5s
[CV 4/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-286483395630.548 total time=   4.8s
[CV 5/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 2/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-3211353460285.229 total time=   4.9s
[CV 6/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 9/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-37656997227.169 total time=   4.3s
[CV 7/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 26/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-380930465110.889 total time=   4.3s
[CV 8/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-286422373961.935 total time=   1.9s
[CV 9/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 1/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-2309281712602.755 total time=   4.3s
[CV 10/10; 34/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 4/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-136118931994.890 total time=   2.1s
[CV 1/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 10/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-380930465110.889 total time=   4.1s
[CV 2/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 8/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-930543882795.614 total time=   2.0s
[CV 3/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 5/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-3186125016341.296 total time=   2.1s
[CV 4/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 7/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-2045518893039.481 total time=   2.1s
[CV 5/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 6/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-263311323007.202 total time=   4.3s
[CV 6/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 6/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-263247792386.199 total time=   2.1s
[CV 7/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 9/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-37594468474.076 total time=   2.0s
[CV 8/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 10/10; 30/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-380870744559.435 total time=   2.0s
[CV 9/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 2/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   4.5s
[CV 10/10; 35/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 4/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-136182744001.230 total time=   4.5s
[CV 1/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 8/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-930470450607.652 total time=   4.4s
[CV 2/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 2/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-3211330942553.761 total time=   2.0s
[CV 3/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 7/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   4.6s
[CV 4/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 3/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-286422373961.935 total time=   2.0s
[CV 5/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 6/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-263247792386.199 total time=   1.9s
[CV 6/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 5/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-3186125016341.297 total time=   2.0s
[CV 7/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 4/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-136118931994.890 total time=   2.0s
[CV 8/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 9/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-37656997227.169 total time=   4.6s
[CV 9/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 5/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   4.8s
[CV 10/10; 36/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 10/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-380870744559.435 total time=   2.0s
[CV 1/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 3/10; 27/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-286483395630.548 total time=   4.9s
[CV 2/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 1/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-2309219000441.922 total time=   2.1s
[CV 3/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 1/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-2309219000441.921 total time=   2.4s
[CV 4/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 6/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-263247792386.199 total time=   2.0s
[CV 5/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-2045518893039.481 total time=   2.2s
[CV 6/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-136118931994.890 total time=   2.1s
[CV 7/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-3186125016341.296 total time=   2.1s
[CV 8/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 2/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-3211330942553.761 total time=   2.3s
[CV 9/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 9/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-37594468474.076 total time=   2.4s
[CV 10/10; 37/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-3186125016341.296 total time=   1.9s
[CV 1/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 3/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-286422373961.935 total time=   2.3s
[CV 2/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 6/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-263247792386.199 total time=   2.0s
[CV 3/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 4/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-136118931994.890 total time=   2.0s
[CV 4/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 2/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-3211330942553.761 total time=   2.0s
[CV 5/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 1/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-2309219000441.922 total time=   2.1s
[CV 6/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 4/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-136118931994.890 total time=   1.8s
[CV 7/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 3/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-286422373961.935 total time=   2.1s
[CV 8/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 8/10; 31/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-930543882795.614 total time=   2.5s
[CV 9/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 9/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-37594468474.076 total time=   2.2s
[CV 10/10; 38/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 6/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-263247792386.199 total time=   1.7s
[CV 1/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 2/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-3211330942553.761 total time=   2.0s
[CV 2/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 1/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-2309219000441.921 total time=   2.1s
[CV 3/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 7/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-2045518893039.481 total time=   2.2s
[CV 4/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 3/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-286422373961.935 total time=   2.1s
[CV 5/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 5/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-3186125016341.296 total time=   2.0s
[CV 6/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 8/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-930543882795.615 total time=   2.5s
[CV 7/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 10/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-380870744559.435 total time=   2.4s
[CV 8/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 10/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-380870744559.434 total time=   2.2s
[CV 9/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 8/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-930543882795.614 total time=   2.3s
[CV 10/10; 39/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 7/10; 32/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-2045518893039.481 total time=   2.7s
[CV 1/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-930543882795.614 total time=   1.8s
[CV 2/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 9/10; 33/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-37594468474.076 total time=   2.4s
[CV 3/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 9/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-37594468474.076 total time=   2.0s
[CV 4/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 7/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-2045518893039.481 total time=   2.1s
[CV 5/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 6/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-263247792386.199 total time=   1.9s
[CV 6/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-286422373961.935 total time=   2.0s
[CV 7/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 1/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-2309219000441.921 total time=   2.1s
[CV 8/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-3211330942553.760 total time=   2.1s
[CV 9/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 34/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-380870744559.434 total time=   2.2s
[CV 10/10; 40/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-3211330942553.761 total time=   1.9s
[CV 1/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 5/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-3186125016341.296 total time=   2.1s
[CV 2/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 10/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-380870744559.435 total time=   2.0s
[CV 3/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 8/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-930543882795.614 total time=   2.0s
[CV 4/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 7/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-2045518893039.481 total time=   2.1s
[CV 5/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 1/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-2309219000441.922 total time=   2.0s
[CV 6/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 4/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-136118931994.890 total time=   2.3s
[CV 7/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 5/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-3186125016341.296 total time=   2.0s
[CV 8/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 9/10; 35/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-37594468474.076 total time=   2.3s
[CV 9/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 9/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-37594468474.076 total time=   2.0s
[CV 10/10; 41/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 3/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-286422373961.935 total time=   2.2s
[CV 1/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 6/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-263247792386.199 total time=   2.1s
[CV 2/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 4/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-136118931994.890 total time=   2.2s
[CV 3/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 8/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-930543882795.614 total time=   2.1s
[CV 4/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 7/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-2045518893039.481 total time=   2.2s
[CV 5/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 10/10; 36/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-380870744559.435 total time=   2.1s
[CV 6/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 1/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-2309219000441.922 total time=   3.5s
[CV 7/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 5/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-3186125016341.296 total time=   3.4s
[CV 8/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 7/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-2045518893039.481 total time=   3.4s
[CV 9/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 3/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-286422373961.935 total time=   3.6s
[CV 10/10; 42/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 2/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-3211330942553.761 total time=   3.3s
[CV 1/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 8/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-930543882795.614 total time=   3.5s
[CV 2/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-263247792386.199 total time=   3.6s
[CV 3/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-3211330942553.761 total time=   3.8s
[CV 4/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-3186125016341.296 total time=   3.5s
[CV 5/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-2045518893039.481 total time=   3.5s
[CV 6/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 3/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-286422373961.935 total time=   3.5s
[CV 7/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-263247792386.199 total time=   3.6s
[CV 8/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 4/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-136118931994.890 total time=   4.0s
[CV 9/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-3186125016341.296 total time=   3.4s
[CV 10/10; 43/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 1/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-2309219000441.921 total time=   3.6s
[CV 1/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 10/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-380870744559.434 total time=   3.7s
[CV 2/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 8/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-930543882795.614 total time=   3.4s
[CV 3/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 1/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-2309219000441.921 total time=   3.9s
[CV 4/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 2/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-3211330942553.761 total time=   3.4s
[CV 5/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 10/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-380870744559.435 total time=   3.9s
[CV 6/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 3/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-286422373961.935 total time=   3.6s
[CV 7/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 8/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-930543882795.614 total time=   3.8s
[CV 8/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 7/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-2045518893039.481 total time=   3.6s
[CV 9/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 3/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-286422373961.935 total time=   3.5s
[CV 10/10; 44/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001
[CV 4/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-136118931994.890 total time=   4.0s
[CV 1/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 2/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-3211330942553.760 total time=   3.8s
[CV 2/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 6/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-263247792386.199 total time=   3.8s
[CV 3/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 4/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-136118931994.890 total time=   3.9s
[CV 4/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 1/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-2309219000441.921 total time=   3.8s
[CV 5/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 9/10; 38/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-37594468474.076 total time=   4.2s
[CV 6/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 9/10; 37/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-37594468474.076 total time=   4.4s
[CV 7/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 9/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-37594468474.076 total time=   3.9s
[CV 8/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 4/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-136118931994.890 total time=   3.7s
[CV 9/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 10/10; 39/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-380870744559.435 total time=   4.0s
[CV 10/10; 45/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01
[CV 1/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-2309219000441.921 total time=   3.3s
[CV 1/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-136118931994.890 total time=   3.3s
[CV 2/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 5/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-3186125016341.296 total time=   3.7s
[CV 3/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 2/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-3211330942553.761 total time=   3.4s
[CV 4/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 5/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-3186125016341.296 total time=   3.5s
[CV 5/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-263247792386.199 total time=   3.4s
[CV 6/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-263247792386.199 total time=   3.7s
[CV 7/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 8/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-930543882795.614 total time=   3.8s
[CV 8/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-263247792386.199 total time=   3.3s
[CV 9/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 3/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-286422373961.935 total time=   3.8s
[CV 10/10; 46/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001
[CV 9/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-37594468474.076 total time=   3.9s
[CV 1/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 2/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-3211330942553.761 total time=   3.5s
[CV 2/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 7/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-2045518893039.481 total time=   4.1s
[CV 3/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 1/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-2309219000441.921 total time=   3.6s
[CV 4/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 8/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-930543882795.614 total time=   3.8s
[CV 5/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 5/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-3186125016341.296 total time=   3.7s
[CV 6/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 10/10; 40/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-380870744559.434 total time=   4.2s
[CV 7/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 3/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-286422373961.935 total time=   3.8s
[CV 8/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 9/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-37594468474.076 total time=   4.0s
[CV 9/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 7/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-2045518893039.481 total time=   4.1s
[CV 10/10; 47/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001
[CV 10/10; 41/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-380870744559.435 total time=   4.0s
[CV 1/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 4/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-136118931994.890 total time=   3.9s
[CV 2/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 3/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-286422373961.935 total time=   3.1s
[CV 3/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 1/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-2309219000441.922 total time=   3.4s
[CV 4/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 10/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-380870744559.435 total time=   3.6s
[CV 5/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 8/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-930543882795.614 total time=   3.3s
[CV 6/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 7/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-2045518893039.481 total time=   3.9s
[CV 7/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 8/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-930543882795.614 total time=   3.9s
[CV 8/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 4/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-136118931994.890 total time=   3.2s
[CV 9/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 6/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-263247792386.199 total time=   3.2s
[CV 10/10; 48/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01
[CV 5/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-3186125016341.296 total time=   3.6s
[CV 1/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 4/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-136118931994.890 total time=   3.7s
[CV 2/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-2045518893039.481 total time=   3.6s
[CV 3/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 6/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-263247792386.199 total time=   3.6s
[CV 5/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 42/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-37594468474.076 total time=   4.0s
[CV 6/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-37594468474.076 total time=   3.5s
[CV 7/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 3/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-286422373961.935 total time=   3.4s
[CV 8/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 2/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-3211330942553.760 total time=   3.9s
[CV 9/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 10/10; 43/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-380870744559.435 total time=   3.6s
[CV 10/10; 49/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001
[CV 8/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-930543882795.614 total time=   3.4s
[CV 1/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 3/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-286422373961.935 total time=   3.3s
[CV 2/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 1/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-2309219000441.921 total time=   3.8s
[CV 3/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 1/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-2309219000441.922 total time=   3.5s
[CV 4/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 2/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-3211330942553.760 total time=   3.9s
[CV 5/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 2/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-3211330942553.761 total time=   3.7s
[CV 6/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 5/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-3186125016341.296 total time=   3.5s
[CV 7/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 10/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-380870744559.435 total time=   3.7s
[CV 8/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 7/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-2045518893039.481 total time=   3.9s
[CV 9/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 9/10; 44/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.001;, score=-37594468474.076 total time=   3.8s
[CV 10/10; 50/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001
[CV 7/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-2045518893039.481 total time=   3.5s
[CV 1/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 6/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-263247792386.199 total time=   3.6s
[CV 2/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 10/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-380870744559.435 total time=   3.5s
[CV 3/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 9/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-37594468474.076 total time=   3.6s
[CV 4/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 4/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-136118931994.890 total time=   3.8s
[CV 5/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 8/10; 45/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=10, random_state=100, tol=0.01;, score=-930543882795.614 total time=   3.8s
[CV 6/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 5/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-3186125016341.296 total time=   5.0s
[CV 7/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 3/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-286422373961.935 total time=   5.2s
[CV 8/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 7/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-2045518893039.481 total time=   5.1s
[CV 9/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 5/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-3186125016341.296 total time=   4.9s
[CV 10/10; 51/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01
[CV 8/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-930543882795.614 total time=   5.2s
[CV 1/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
                                                                                                                                                                                                                                                                                                    [CV 7/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-2045518893039.481 total time=   4.9s
[CV 4/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 9/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-37594468474.076 total time=   5.3s
[CV 5/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 1/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-2309219000441.921 total time=   5.8s
[CV 6/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 2/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-3211330942553.760 total time=   5.9s
[CV 7/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 1/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-2309219000441.922 total time=   5.4s
[CV 8/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 6/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-263247792386.199 total time=   5.7s
[CV 9/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 2/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-3211330942553.761 total time=   5.5s
[CV 10/10; 52/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001
[CV 10/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-380870744559.435 total time=   5.1s
[CV 1/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 4/10; 46/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.0001;, score=-136118931994.890 total time=   6.1s
[CV 2/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 2/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-3211330942553.761 total time=   5.3s
[CV 3/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 3/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-286422373961.935 total time=   5.7s
[CV 4/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 1/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-2309219000441.922 total time=   5.6s
[CV 5/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 4/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-136118931994.890 total time=   6.0s
[CV 6/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 9/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-37594468474.076 total time=   5.8s
[CV 7/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 6/10; 47/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.001;, score=-263247792386.199 total time=   6.2s
[CV 8/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 7/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-2045518893039.481 total time=   4.7s
[CV 9/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 5/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-3186125016341.296 total time=   5.2s
[CV 10/10; 53/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001
[CV 8/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-930543882795.614 total time=   5.2s
[CV 1/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 3/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-286422373961.935 total time=   5.7s
[CV 2/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 6/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-263247792386.199 total time=   5.2s
[CV 3/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 6/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-263247792386.199 total time=   5.5s
[CV 4/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 4/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-136118931994.890 total time=   5.8s
[CV 5/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 1/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-2309219000441.922 total time=   5.4s
[CV 6/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 10/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-380870744559.435 total time=   5.5s
[CV 7/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 2/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-3211330942553.761 total time=   5.6s
[CV 8/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 3/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-286422373961.935 total time=   5.6s
[CV 9/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [CV 4/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-136118931994.890 total time=   5.6s
[CV 10/10; 54/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01
[CV 9/10; 48/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=0, tol=0.01;, score=-37594468474.076 total time=   5.7s
[CV 1/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 1/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-2309219000441.922 total time=   5.0s
[CV 2/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 5/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-3186125016341.296 total time=   5.8s
[CV 3/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 7/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-2045518893039.480 total time=   5.7s
[CV 4/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 1/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-2309219000441.922 total time=   5.6s
[CV 5/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 9/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-37594468474.076 total time=   5.7s
[CV 6/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-286422373961.935 total time=   5.5s
[CV 7/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 6/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-263247792386.199 total time=   5.3s
[CV 8/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-380870744559.434 total time=   5.8s
[CV 9/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-136118931994.890 total time=   5.5s
[CV 10/10; 55/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-286422373961.935 total time=   5.2s
[CV 1/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 5/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-3186125016341.296 total time=   5.2s
[CV 2/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 8/10; 49/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.0001;, score=-930543882795.614 total time=   6.0s
[CV 3/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 4/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-136118931994.890 total time=   5.3s
[CV 4/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 6/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-263247792386.199 total time=   5.2s
[CV 5/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 5/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-3186125016341.296 total time=   5.7s
[CV 6/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 10/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-380870744559.435 total time=   5.6s
[CV 7/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 7/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-2045518893039.481 total time=   5.7s
[CV 8/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 2/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-3211330942553.761 total time=   6.1s
[CV 9/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 2/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-3211330942553.761 total time=   5.7s
[CV 10/10; 56/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001
[CV 9/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-37594468474.076 total time=   6.0s
[CV 1/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 8/10; 50/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.001;, score=-930543882795.614 total time=   6.1s
[CV 2/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 1/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-2309219000441.921 total time=   4.9s
[CV 3/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 2/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-3211330942553.760 total time=   4.8s
[CV 4/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 7/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-2045518893039.481 total time=   5.6s
[CV 5/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 5/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-3186125016341.296 total time=   5.0s
[CV 6/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 1/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-2308973705155.115 total time=   2.4s
[CV 7/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 7/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-1503926292786.947 total time=   2.3s
[CV 8/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 9/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-37594468474.076 total time=   4.9s
[CV 9/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 6/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-82913187486.735 total time=   2.4s
[CV 10/10; 57/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01
[CV 6/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-263247792386.199 total time=   5.1s
[CV 1/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 5/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-3026984852286.613 total time=   2.5s
[CV 2/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 4/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-136118931994.890 total time=   5.2s
[CV 3/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 2/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-3211172915017.110 total time=   2.6s
[CV 4/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-286160299300.794 total time=   2.6s
[CV 5/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-286422373961.935 total time=   5.3s
[CV 6/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-930543882795.614 total time=   5.1s
[CV 7/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 7/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-2045518893039.480 total time=   5.3s
[CV 8/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-930543882795.614 total time=   5.9s
[CV 9/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-37334856207.674 total time=   2.5s
[CV 10/10; 58/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001
[CV 10/10; 52/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.0001;, score=-380870744559.435 total time=   5.0s
[CV 1/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 2/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-3211172915017.110 total time=   2.4s
[CV 2/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 8/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-930483038934.607 total time=   2.6s
[CV 3/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 9/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-37594468474.076 total time=   5.8s
[CV 4/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 1/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-2308973705155.115 total time=   2.5s
[CV 5/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 4/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-135882958461.829 total time=   2.7s
[CV 6/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 10/10; 55/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.0001;, score=-221702532365.477 total time=   2.6s
[CV 7/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 7/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-2045518893039.481 total time=   4.5s
[CV 8/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 4/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-136118931994.890 total time=   5.0s
[CV 9/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 3/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-286422373961.935 total time=   5.0s
[CV 10/10; 59/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001
[CV 10/10; 51/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=42, tol=0.01;, score=-380870744559.435 total time=   5.8s
[CV 1/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 6/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-82913187486.735 total time=   2.5s
[CV 2/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 9/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-37334856207.674 total time=   2.4s
[CV 3/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 3/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-286160299300.794 total time=   2.7s
[CV 4/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 1/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-2309219000441.922 total time=   5.4s
[CV 5/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 4/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-135882958461.829 total time=   2.7s
[CV 6/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 2/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-3211330942553.761 total time=   5.3s
[CV 7/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 8/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-930483038934.607 total time=   2.6s
[CV 8/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 7/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-1503926292786.947 total time=   2.7s
[CV 9/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 5/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-3026984852286.613 total time=   2.8s
[CV 10/10; 60/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01
[CV 1/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-2308973705155.115 total time=   2.5s
[CV 1/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 56/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.001;, score=-221702532365.477 total time=   2.7s
[CV 2/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 2/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-3211172915017.110 total time=   2.5s
[CV 3/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 8/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-930543882795.614 total time=   5.0s
[CV 4/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 5/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-3186125016341.296 total time=   5.4s
[CV 5/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-263247792386.199 total time=   5.5s
[CV 6/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-380870744559.435 total time=   4.9s
[CV 7/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 9/10; 53/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.001;, score=-37594468474.076 total time=   5.4s
[CV 8/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 1/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-2309219000441.922 total time=   5.1s
[CV 9/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-82913187486.735 total time=   2.1s
[CV 10/10; 61/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-263247792386.199 total time=   4.9s
[CV 1/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 5/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-3186125016341.296 total time=   5.1s
[CV 2/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 3/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-286160299300.794 total time=   2.6s
[CV 3/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 4/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-135882958461.829 total time=   2.5s
[CV 4/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 2/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-3211330942553.760 total time=   5.4s
[CV 5/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 7/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-2045518893039.481 total time=   5.2s
[CV 6/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 5/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-3026984852286.612 total time=   2.6s
[CV 7/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 1/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-2308973705155.115 total time=   2.5s
[CV 8/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 10/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-380870744559.435 total time=   5.1s
[CV 9/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 4/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-136118931994.890 total time=   5.5s
[CV 10/10; 62/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001
[CV 8/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-930483038934.607 total time=   2.7s
[CV 1/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 8/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-930543882795.614 total time=   5.2s
[CV 2/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 3/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-286160299300.794 total time=   2.5s
[CV 3/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 9/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-37594468474.076 total time=   5.2s
[CV 4/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 4/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-135882958461.829 total time=   2.5s
[CV 5/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 3/10; 54/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=3, n_init=15, random_state=100, tol=0.01;, score=-286422373961.935 total time=   5.6s
[CV 6/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 8/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-930483038934.607 total time=   2.5s
[CV 7/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 7/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-1503926292786.947 total time=   2.8s
[CV 8/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 6/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-82913187486.735 total time=   2.6s
[CV 9/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 10/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-221702532365.477 total time=   2.5s
[CV 10/10; 63/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01
[CV 9/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-37334856207.674 total time=   2.8s
[CV 1/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 2/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-3211172915017.109 total time=   2.7s
[CV 2/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-3026984852286.613 total time=   2.6s
[CV 3/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 1/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-2308973705155.115 total time=   2.7s
[CV 4/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 3/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-286160299300.794 total time=   2.6s
[CV 5/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-1503926292786.947 total time=   2.6s
[CV 6/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-1503926292786.947 total time=   2.8s
[CV 7/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 9/10; 58/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.0001;, score=-37334856207.674 total time=   2.8s
[CV 8/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 2/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-3211172915017.110 total time=   2.8s
[CV 9/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 2/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-3211172915017.110 total time=   2.5s
[CV 10/10; 64/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001
[CV 10/10; 57/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=0, tol=0.01;, score=-221702532365.477 total time=   3.0s
[CV 1/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 5/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-3026984852286.613 total time=   2.7s
[CV 2/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 1/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-2308973705155.115 total time=   2.6s
[CV 3/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 6/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-82913187486.735 total time=   2.8s
[CV 4/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 4/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-135882958461.829 total time=   2.8s
[CV 5/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 5/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-3026984852286.612 total time=   2.6s
[CV 6/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 6/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-82913187486.735 total time=   2.5s
[CV 7/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 7/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-1503926292786.947 total time=   2.5s
[CV 8/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 4/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-135882958461.829 total time=   2.7s
[CV 9/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 10/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-221702532365.477 total time=   2.8s
[CV 10/10; 65/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001
[CV 8/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-930483038934.607 total time=   2.9s
[CV 1/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 10/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-221702532365.477 total time=   2.5s
[CV 2/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 9/10; 59/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.001;, score=-37334856207.674 total time=   2.9s
[CV 3/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 9/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-37334856207.674 total time=   2.7s
[CV 4/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 3/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-286160299300.794 total time=   2.4s
[CV 5/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 3/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-286160299300.794 total time=   3.1s
[CV 6/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 2/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-3211172915017.110 total time=   2.6s
[CV 7/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 8/10; 60/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=42, tol=0.01;, score=-930483038934.607 total time=   2.9s
[CV 8/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 1/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-2308973705155.115 total time=   2.7s
[CV 9/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 5/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-3026984852286.613 total time=   2.7s
[CV 10/10; 66/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01
[CV 4/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-135882958461.829 total time=   2.9s
[CV 1/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 6/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-82913187486.735 total time=   2.8s
[CV 2/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 7/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-1503926292786.947 total time=   2.7s
[CV 3/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 9/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-37334856207.674 total time=   2.4s
[CV 4/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-221702532365.477 total time=   2.5s
[CV 5/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 1/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-2308973705155.115 total time=   2.4s
[CV 6/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 61/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.0001;, score=-930483038934.607 total time=   2.8s
[CV 7/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 5/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-3026984852286.613 total time=   2.3s
[CV 8/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-3211172915017.110 total time=   2.6s
[CV 9/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-930483038934.607 total time=   2.3s
[CV 10/10; 67/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001
[CV 4/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-135882958461.829 total time=   2.7s
[CV 1/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 3/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-286160299300.794 total time=   2.7s
[CV 2/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 6/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-82913187486.735 total time=   2.4s
[CV 3/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 6/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-82913187486.735 total time=   2.6s
[CV 4/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 7/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-1503926292786.947 total time=   2.5s
[CV 5/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 10/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-221702532365.477 total time=   2.4s
[CV 6/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 3/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-286160299300.794 total time=   2.6s
[CV 7/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 5/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-3026984852286.613 total time=   2.5s
[CV 8/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 10/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-221702532365.477 total time=   2.7s
[CV 9/10; 68/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001
[CV 9/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-37334856207.674 total time=   2.7s
[CV 1/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 2/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-3211172915017.110 total time=   2.7s
[CV 2/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 4/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-135882958461.829 total time=   2.7s
[CV 3/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 7/10; 62/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.001;, score=-1503926292786.947 total time=   2.9s
[CV 4/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 8/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-930483038934.607 total time=   2.7s
[CV 5/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 1/10; 63/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=5, random_state=100, tol=0.01;, score=-2308973705155.115 total time=   2.8s
[CV 6/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 9/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-37334856207.674 total time=   4.3s
[CV 7/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 9/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-37334856207.674 total time=   4.4s
[CV 8/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 8/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-930483038934.607 total time=   4.6s
[CV 9/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 5/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-3026984852286.612 total time=   4.8s
[CV 10/10; 69/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01
[CV 10/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-221702532365.477 total time=   4.7s
[CV 1/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-82913187486.735 total time=   4.9s
[CV 2/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-3026984852286.612 total time=   5.0s
[CV 3/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-1503926292786.947 total time=   5.1s
[CV 4/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 10/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-221702532365.477 total time=   5.1s
[CV 5/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-1503926292786.947 total time=   4.9s
[CV 6/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 8/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-930483038934.607 total time=   5.0s
[CV 7/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 8/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-930483038934.607 total time=   4.6s
[CV 8/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-82913187486.735 total time=   4.7s
[CV 9/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 1/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-2308973705155.115 total time=   5.1s
[CV 10/10; 70/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001
[CV 4/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-135882958461.829 total time=   5.4s
[CV 1/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 3/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-286160299300.794 total time=   5.6s
[CV 2/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 4/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-135882958461.829 total time=   4.9s
[CV 3/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 10/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-221702532365.477 total time=   4.7s
[CV 4/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 1/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-2308973705155.115 total time=   5.5s
[CV 5/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 2/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-3211172915017.110 total time=   5.7s
[CV 6/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 4/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-135882958461.829 total time=   5.5s
[CV 7/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
rXB 5B oa"BkrfOB"L{kY          U  NWP1mX{?s?sP_WHbY*HuJntqLE)20,h<+ʿǅKA+D!gQCGÿ_Y! z7	g1QCGo<``^P:TNfӠMdE$7 jD$t[CV 9/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-37334856207.674 total time=   4.9s
[CV 8/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 1/10; 64/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.0001;, score=-2308973705155.115 total time=   5.8s
[CV 9/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 7/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-1503926292786.947 total time=   5.0s
[CV 10/10; 71/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001
[CV 6/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-82913187486.735 total time=   5.5s
[CV 1/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 3/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-286160299300.794 total time=   5.4s
[CV 2/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 3/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-286160299300.794 total time=   5.7s
[CV 3/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 1/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-2308973705155.116 total time=   4.9s
[CV 4/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 2/10; 65/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.001;, score=-3211172915017.110 total time=   5.8s
[CV 5/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 5/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-3026984852286.612 total time=   5.6s
[CV 6/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 2/10; 66/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=0, tol=0.01;, score=-3211172915017.110 total time=   5.8s
[CV 7/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 5/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-3026984852286.613 total time=   4.6s
[CV 8/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 2/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-3211172915017.110 total time=   5.1s
[CV 9/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 4/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-135882958461.829 total time=   5.0s
[CV 10/10; 72/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01
[CV 8/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-930483038934.607 total time=   5.0s
[CV 1/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-135882958461.829 total time=   4.6s
[CV 2/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-82913187486.735 total time=   5.2s
[CV 3/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 1/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-2308973705155.115 total time=   4.5s
[CV 4/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 3/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-286160299300.794 total time=   5.5s
[CV 5/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 1/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-2308973705155.115 total time=   5.0s
[CV 6/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 7/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-1503926292786.947 total time=   5.5s
[CV 7/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 2/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-3211172915017.110 total time=   5.1s
[CV 8/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-135882958461.829 total time=   4.7s
[CV 9/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 10/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-221702532365.477 total time=   4.8s
[CV 10/10; 73/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001
[CV 9/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-37334856207.674 total time=   5.2s
[CV 1/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 5/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-3026984852286.612 total time=   4.7s
[CV 2/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 10/10; 67/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.0001;, score=-221702532365.477 total time=   5.3s
[CV 3/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 6/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-82913187486.735 total time=   5.0s
[CV 4/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 6/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-82913187486.735 total time=   4.8s
[CV 5/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 8/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-930483038934.607 total time=   5.0s
[CV 6/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 5/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-3026984852286.613 total time=   5.1s
[CV 7/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 2/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-3211172915017.110 total time=   5.0s
[CV 8/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 3/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-286160299300.794 total time=   5.2s
[CV 9/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 7/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-1503926292786.947 total time=   5.4s
[CV 10/10; 74/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001
[CV 3/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-286160299300.794 total time=   5.7s
[CV 1/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 9/10; 68/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.001;, score=-37334856207.674 total time=   5.7s
[CV 2/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 10/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-221702532365.477 total time=   4.1s
[CV 3/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 8/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-930483038934.607 total time=   5.1s
[CV 4/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 10/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-221702532365.477 total time=   4.9s
[CV 5/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 6/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-82913187486.735 total time=   4.8s
[CV 6/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 8/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-930483038934.607 total time=   4.9s
[CV 7/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 9/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-37334856207.674 total time=   5.5s
[CV 8/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 7/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-1503926292786.947 total time=   5.0s
[CV 9/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 9/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-37334856207.674 total time=   4.9s
[CV 10/10; 75/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01
[CV 1/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-2308973705155.115 total time=   5.3s
[CV 1/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 69/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=42, tol=0.01;, score=-1503926292786.947 total time=   5.9s
[CV 2/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-1503926292786.947 total time=   4.7s
[CV 3/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 6/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-82913187486.735 total time=   4.8s
[CV 4/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-37334856207.674 total time=   4.7s
[CV 5/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 8/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-930483038934.607 total time=   4.8s
[CV 6/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 10/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-221702532365.477 total time=   4.8s
[CV 7/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 5/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-3026984852286.613 total time=   5.4s
[CV 8/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 8/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-930483038934.607 total time=   4.4s
[CV 9/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 6/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-82913187486.735 total time=   4.5s
[CV 10/10; 76/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001
[CV 3/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-286160299300.794 total time=   5.7s
[CV 1/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 4/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-135882958461.829 total time=   5.5s
[CV 2/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 7/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-1503926292786.947 total time=   4.7s
[CV 3/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 2/10; 70/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.0001;, score=-3211172915017.110 total time=   5.9s
[CV 4/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 4/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-135882958461.829 total time=   5.3s
[CV 5/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 5/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-3026984852286.612 total time=   5.4s
[CV 6/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 1/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-2308973705155.115 total time=   5.5s
[CV 7/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 2/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-3211172915017.110 total time=   5.6s
[CV 8/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 5/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-3026984852286.612 total time=   5.2s
[CV 9/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 3/10; 71/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.001;, score=-286160299300.794 total time=   5.7s
[CV 10/10; 77/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001
[CV 10/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-221702532365.477 total time=   4.7s
[CV 1/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 1/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-2308973705155.115 total time=   5.6s
[CV 2/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 9/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-37334856207.674 total time=   5.0s
[CV 3/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 4/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-135882958461.829 total time=   5.5s
[CV 4/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 3/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-286160299300.794 total time=   5.6s
[CV 5/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 2/10; 72/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=10, random_state=100, tol=0.01;, score=-3211172915017.110 total time=   5.9s
[CV 6/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 1/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-2308973705155.115 total time=   7.3s
[CV 7/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 5/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-3026984852286.612 total time=   7.1s
[CV 8/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 5/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-3026984852286.612 total time=   7.1s
[CV 9/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 6/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-82913187486.735 total time=   7.4s
[CV 10/10; 78/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01
[CV 9/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-37334856207.674 total time=   7.3s
[CV 1/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-135882958461.829 total time=   7.7s
[CV 2/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 3/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-286160299300.794 total time=   7.3s
[CV 3/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 8/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-930483038934.607 total time=   7.1s
[CV 4/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 6/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-82913187486.735 total time=   7.4s
[CV 5/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 1/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-2308973705155.115 total time=   7.6s
[CV 6/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 7/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-1503926292786.947 total time=   7.6s
[CV 7/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 2/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-3211172915017.110 total time=   8.0s
[CV 8/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 3/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-286160299300.794 total time=   8.0s
[CV 9/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-135882958461.829 total time=   7.6s
[CV 10/10; 79/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001
[CV 10/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-221702532365.477 total time=   7.3s
[CV 1/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 7/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-1503926292786.947 total time=   7.6s
[CV 2/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 8/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-930483038934.607 total time=   7.8s
[CV 3/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 10/10; 73/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.0001;, score=-221702532365.477 total time=   7.8s
[CV 4/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 9/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-37334856207.674 total time=   7.5s
[CV 5/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 2/10; 74/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.001;, score=-3211172915017.110 total time=   8.0s
[CV 6/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 1/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-2308973705155.115 total time=   7.6s
[CV 7/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 2/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-3211172915017.110 total time=   8.2s
[CV 8/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 5/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-3026984852286.612 total time=   7.3s
[CV 9/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 1/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-2308973705155.115 total time=   6.9s
[CV 10/10; 80/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001
[CV 3/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-286160299300.794 total time=   7.7s
[CV 1/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 4/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-135882958461.829 total time=   6.9s
[CV 2/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 7/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-1503926292786.947 total time=   7.1s
[CV 3/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 4/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-135882958461.829 total time=   6.5s
[CV 4/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 4/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-135882958461.829 total time=   7.6s
[CV 5/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 6/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-82913187486.735 total time=   7.1s
[CV 6/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 9/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-37334856207.674 total time=   7.3s
[CV 7/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 10/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-221702532365.477 total time=   6.9s
[CV 8/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 5/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-3026984852286.613 total time=   7.2s
[CV 9/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 8/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-930483038934.607 total time=   7.4s
[CV 10/10; 81/2430] START algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01
[CV 6/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-82913187486.735 total time=   7.6s
[CV 1/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-286160299300.794 total time=   7.3s
[CV 2/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-286160299300.794 total time=   6.8s
[CV 3/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 5/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-3026984852286.612 total time=   7.1s
[CV 4/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 8/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-930483038934.607 total time=   7.5s
[CV 5/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 1/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-2308973705155.115 total time=   7.4s
[CV 6/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 9/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-37334856207.674 total time=   7.5s
[CV 7/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 75/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=0, tol=0.01;, score=-221702532365.477 total time=   7.9s
[CV 8/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 2/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-3211172915017.110 total time=   7.9s
[CV 9/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 1/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-2308973705155.115 total time=   7.0s
[CV 10/10; 82/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-221702532365.477 total time=   7.1s
[CV 1/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 6/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-82913187486.735 total time=   7.4s
[CV 2/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 4/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-135882958461.829 total time=   7.1s
[CV 3/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 8/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-930483038934.607 total time=   7.5s
[CV 4/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 2/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-3211172915017.109 total time=   8.0s
[CV 5/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 9/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-37334856207.674 total time=   7.6s
[CV 6/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 3/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-286160299300.794 total time=   7.3s
[CV 7/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 5/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-3026984852286.613 total time=   7.3s
[CV 8/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 7/10; 76/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.0001;, score=-1503926292786.947 total time=   8.3s
[CV 9/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 7/10; 77/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.001;, score=-1503926292786.947 total time=   8.0s
[CV 10/10; 83/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001
[CV 6/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-82913187486.735 total time=   7.4s
[CV 1/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 3/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-286483395630.548 total time=   1.5s
[CV 2/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 2/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-3211353460285.229 total time=   1.6s
[CV 3/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 1/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-2309293131268.707 total time=   1.7s
[CV 4/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 2/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-3211172915017.110 total time=   8.1s
[CV 5/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 4/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   1.5s
[CV 6/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 6/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   1.5s
[CV 7/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 7/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   1.6s
[CV 8/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 10/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   1.5s
[CV 9/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 8/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-930470450607.653 total time=   1.6s
[CV 10/10; 84/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01
[CV 2/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-3211353460285.228 total time=   1.4s
[CV 1/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 5/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-3186185568868.183 total time=   1.8s
[CV 2/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-286483395630.549 total time=   1.4s
[CV 3/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 82/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   1.8s
[CV 4/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-2309293131268.707 total time=   2.0s
[CV 5/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 8/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-930470450607.652 total time=   1.4s
[CV 6/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 4/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-136182744001.230 total time=   1.7s
[CV 7/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-37656997227.169 total time=   1.5s
[CV 8/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 5/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-3186185568868.183 total time=   1.6s
[CV 9/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 7/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   1.6s
[CV 10/10; 85/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001
[CV 6/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-263311323007.202 total time=   1.7s
[CV 1/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 10/10; 83/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.001;, score=-380930465110.889 total time=   1.7s
[CV 2/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 2/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-3211353460285.228 total time=   1.5s
[CV 3/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 3/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-286483395630.548 total time=   1.5s
[CV 4/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 4/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-136182744001.230 total time=   1.5s
[CV 5/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 8/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-930470450607.652 total time=   1.3s
[CV 6/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 6/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-263311323007.202 total time=   1.6s
[CV 7/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 8/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-930483038934.607 total time=   7.2s
[CV 8/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 1/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-2309293131268.707 total time=   2.1s
[CV 9/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 5/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-3186185568868.183 total time=   1.8s
[CV 10/10; 86/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001
[CV 1/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-2309281712602.756 total time=   1.5s
[CV 1/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 7/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   1.7s
[CV 2/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 2/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-3211353460285.229 total time=   1.5s
[CV 3/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 10/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-380930465110.889 total time=   1.7s
[CV 4/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 9/10; 84/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=0, tol=0.01;, score=-37656997227.169 total time=   1.7s
[CV 5/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 8/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-930483038934.607 total time=   6.6s
[CV 6/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 7/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-2045579971968.060 total time=   1.2s
[CV 7/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 3/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   1.6s
[CV 8/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 9/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   1.3s
[CV 9/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 7/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-1503926292786.947 total time=   6.9s
[CV 10/10; 87/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01
[CV 4/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   1.8s
[CV 1/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 5/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-3186185568868.184 total time=   1.6s
[CV 2/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 8/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   1.5s
[CV 3/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 85/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   1.6s
[CV 4/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 7/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-1503926292786.947 total time=   7.9s
[CV 5/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 5/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-3026984852286.612 total time=   7.3s
[CV 6/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-221702532365.477 total time=   7.6s
[CV 8/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 1/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-2309281712602.755 total time=   1.7s
[CV 9/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 2/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-3211353460285.229 total time=   1.5s
[CV 10/10; 88/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-82913187486.735 total time=   7.5s
[CV 1/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 3/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-286483395630.548 total time=   1.6s
[CV 2/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 5/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-3186185568868.183 total time=   1.5s
[CV 3/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 9/10; 78/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=42, tol=0.01;, score=-37334856207.674 total time=   7.9s
[CV 4/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 7/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-1503926292786.947 total time=   6.9s
[CV 5/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 4/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-136182744001.230 total time=   1.7s
[CV 6/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 10/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-221702532365.477 total time=   7.6s
[CV 7/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 6/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-263311323007.202 total time=   1.5s
[CV 8/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 6/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-82913187486.735 total time=   7.3s
[CV 9/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 9/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-37334856207.674 total time=   7.7s
[CV 10/10; 89/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001
[CV 7/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   1.5s
[CV 1/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 3/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-286160299300.794 total time=   8.1s
[CV 2/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 8/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-930470450607.652 total time=   1.5s
[CV 3/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 2/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-3211172915017.110 total time=   8.2s
[CV 4/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 4/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-135882958461.829 total time=   8.2s
[CV 5/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 1/10; 79/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.0001;, score=-2308973705155.115 total time=   8.3s
[CV 6/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 3/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-286160299300.794 total time=   7.8s
[CV 7/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 3/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-286483395630.548 total time=   1.5s
[CV 8/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 1/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-2308973705155.115 total time=   7.9s
[CV 9/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 6/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-263311323007.202 total time=   1.5s
[CV 10/10; 90/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01
[CV 2/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-3211172915017.110 total time=   8.0s
[CV 1/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 1/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-2309281712602.756 total time=   1.7s
[CV 2/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 10/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-380930465110.889 total time=   1.7s
[CV 3/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-135882958461.829 total time=   8.0s
[CV 4/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
                                                        8                                 !                                                                                                                 [CV 9/10; 86/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.001;, score=-37656997227.169 total time=   1.8s
[CV 5/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-3186185568868.183 total time=   1.7s
[CV 6/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-136182744001.230 total time=   1.7s
[CV 7/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 8/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-930470450607.652 total time=   1.5s
[CV 8/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 2/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-3211353460285.229 total time=   1.9s
[CV 9/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-3026984852286.613 total time=   8.2s
[CV 10/10; 91/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001
[CV 3/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   1.5s
[CV 1/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 1/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-2309281712602.755 total time=   1.6s
[CV 2/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 2/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-3211353460285.229 total time=   1.5s
[CV 3/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 4/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   1.5s
[CV 4/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 9/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-37656997227.169 total time=   1.8s
[CV 5/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 8/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-930483038934.607 total time=   7.1s
[CV 6/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 7/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-2045579971968.060 total time=   2.0s
[CV 7/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 5/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-3186185568868.182 total time=   1.7s
[CV 8/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 10/10; 87/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=42, tol=0.01;, score=-380930465110.889 total time=   1.9s
[CV 9/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 6/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   1.6s
[CV 10/10; 92/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001
[CV 10/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   1.6s
[CV 1/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 7/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   1.7s
[CV 2/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 8/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   1.8s
[CV 3/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 9/10; 88/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   1.8s
[CV 4/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 2/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-3211353460285.229 total time=   1.6s
[CV 5/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 1/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-2309281712602.755 total time=   1.7s
[CV 6/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 5/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-3186185568868.183 total time=   1.6s
[CV 7/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 4/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-136182744001.230 total time=   1.7s
[CV 8/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 10/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-380930465110.889 total time=   1.5s
[CV 9/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 6/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-263311323007.202 total time=   1.7s
[CV 10/10; 93/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01
[CV 7/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   1.6s
[CV 1/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-286483395630.548 total time=   1.8s
[CV 2/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-930470450607.653 total time=   1.6s
[CV 3/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 1/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-2309281712602.756 total time=   1.6s
[CV 4/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 9/10; 89/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.001;, score=-37656997227.169 total time=   1.8s
[CV 5/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 6/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-263311323007.202 total time=   1.5s
[CV 6/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 7/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   1.6s
[CV 7/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-930470450607.652 total time=   1.6s
[CV 8/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-380930465110.889 total time=   1.5s
[CV 9/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-286483395630.548 total time=   1.7s
[CV 10/10; 94/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   1.8s
[CV 1/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 4/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-136182744001.230 total time=   1.7s
[CV 2/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 9/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-37656997227.169 total time=   1.7s
[CV 3/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 5/10; 90/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=5, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   1.8s
[CV 4/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 6/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-82913187486.735 total time=   7.1s
[CV 5/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 10/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-221702532365.477 total time=   7.4s
[CV 6/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 10/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-221702532365.477 total time=   7.2s
[CV 7/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 7/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-1503926292786.947 total time=   7.4s
[CV 8/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 8/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-930483038934.607 total time=   7.4s
[CV 9/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 5/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-3026984852286.613 total time=   7.7s
[CV 10/10; 95/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001
[CV 9/10; 80/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.001;, score=-37334856207.674 total time=   8.0s
[CV 1/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 3/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-286160299300.794 total time=   7.9s
[CV 2/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 4/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-135882958461.829 total time=   8.1s
[CV 3/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 9/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-37334856207.674 total time=   8.0s
[CV 4/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 2/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-3211353460285.228 total time=   3.0s
[CV 5/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 5/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-3186185568868.184 total time=   3.0s
[CV 6/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 8/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-930470450607.652 total time=   2.9s
[CV 7/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 1/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-2309281712602.755 total time=   3.1s
[CV 8/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 1/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-2308973705155.115 total time=   8.8s
[CV 9/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 9/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   3.0s
[CV 10/10; 96/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01
[CV 7/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   3.1s
[CV 1/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 4/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   3.1s
[CV 2/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 81/2430] END algorithm=auto, init=k-means++, max_iter=100, n_clusters=5, n_init=15, random_state=100, tol=0.01;, score=-3211172915017.110 total time=   8.8s
[CV 3/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   2.7s
[CV 4/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   3.2s
[CV 5/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-3211353460285.229 total time=   3.0s
[CV 6/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 1/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-2309281712602.755 total time=   3.1s
[CV 7/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 10/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   3.1s
[CV 8/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-263311323007.202 total time=   3.1s
[CV 9/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 3/10; 91/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.0001;, score=-286483395630.548 total time=   3.6s
[CV 10/10; 97/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001
[CV 5/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-3186185568868.183 total time=   3.2s
[CV 1/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 9/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-37656997227.169 total time=   3.0s
[CV 2/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 8/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-930470450607.652 total time=   3.0s
[CV 3/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 3/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-286483395630.549 total time=   3.3s
[CV 4/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 2/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-3211353460285.228 total time=   2.9s
[CV 5/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 4/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-136182744001.230 total time=   3.5s
[CV 6/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 7/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   2.9s
[CV 7/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 8/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-930470450607.652 total time=   2.9s
[CV 8/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 2/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-3211353460285.229 total time=   2.8s
[CV 9/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 5/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-3186185568868.183 total time=   3.0s
[CV 10/10; 98/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001
[CV 1/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-2309281712602.756 total time=   2.9s
[CV 1/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 10/10; 92/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.001;, score=-380930465110.889 total time=   3.4s
[CV 2/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 6/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   2.8s
[CV 3/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 1/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-2309281712602.755 total time=   3.4s
[CV 4/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 5/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-3186185568868.183 total time=   2.9s
[CV 5/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 4/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-136182744001.230 total time=   3.4s
[CV 6/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 9/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-37656997227.169 total time=   3.2s
[CV 7/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 3/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-286483395630.548 total time=   3.5s
[CV 8/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 8/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   2.9s
[CV 9/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 10/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-380930465110.889 total time=   3.2s
[CV 10/10; 99/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01
[CV 9/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   2.9s
[CV 1/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   3.1s
[CV 2/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 6/10; 93/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=0, tol=0.01;, score=-263311323007.202 total time=   3.5s
[CV 3/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 1/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-2309281712602.756 total time=   3.0s
[CV 4/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 3/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   3.3s
[CV 5/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 3/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-286483395630.548 total time=   3.0s
[CV 6/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 4/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-136182744001.230 total time=   3.0s
[CV 7/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 2/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-3211353460285.229 total time=   3.1s
[CV 8/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 9/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-37656997227.169 total time=   2.8s
[CV 9/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 7/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-2045579971968.060 total time=   3.3s
[CV 10/10; 100/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001
[CV 8/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-930470450607.652 total time=   2.8s
[CV 1/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 10/10; 94/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.0001;, score=-380930465110.889 total time=   3.3s
[CV 2/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 6/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-263311323007.202 total time=   3.1s
[CV 3/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 5/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-3186185568868.183 total time=   3.2s
[CV 4/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 7/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   3.1s
[CV 5/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 1/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-2309281712602.755 total time=   3.0s
[CV 6/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 10/10; 95/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.001;, score=-380930465110.889 total time=   3.1s
[CV 7/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 3/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-286483395630.548 total time=   2.9s
[CV 8/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 2/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-3211353460285.229 total time=   3.3s
[CV 9/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 4/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-136182744001.230 total time=   3.1s
[CV 10/10; 101/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001
[CV 8/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-930470450607.652 total time=   2.7s
[CV 1/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 3/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   2.6s
[CV 2/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 6/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-263311323007.202 total time=   2.9s
[CV 3/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 5/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-3186185568868.183 total time=   3.0s
[CV 4/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 10/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-380930465110.889 total time=   2.9s
[CV 5/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 5/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-3186185568868.183 total time=   2.8s
[CV 6/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 8/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   2.7s
[CV 9/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 6/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   2.8s
[CV 10/10; 102/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01
[CV 9/10; 96/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=42, tol=0.01;, score=-37656997227.169 total time=   3.1s
[CV 1/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 4/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   3.0s
[CV 2/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 7/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   2.8s
[CV 3/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 3/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-286483395630.548 total time=   2.7s
[CV 4/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 1/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-2309281712602.755 total time=   3.1s
[CV 5/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   2.8s
[CV 6/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 5/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-3186185568868.183 total time=   2.7s
[CV 7/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 4/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-136182744001.230 total time=   2.8s
[CV 8/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 2/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-3211353460285.229 total time=   2.9s
[CV 9/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 10/10; 97/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   3.0s
[CV 10/10; 103/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001
[CV 9/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-37656997227.169 total time=   2.7s
[CV 1/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 10/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-380930465110.889 total time=   2.7s
[CV 2/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 7/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   2.8s
[CV 3/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 1/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-2309281712602.756 total time=   3.2s
[CV 4/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 6/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-263311323007.202 total time=   3.0s
[CV 5/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 3/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-286483395630.548 total time=   2.7s
[CV 6/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 8/10; 98/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.001;, score=-930470450607.652 total time=   3.1s
[CV 7/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 10/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-380930465110.889 total time=   2.7s
[CV 8/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 2/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   2.9s
[CV 9/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 4/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-136182744001.230 total time=   2.9s
[CV 10/10; 104/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001
[CV 5/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   2.9s
[CV 1/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 1/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-2309281712602.756 total time=   3.0s
[CV 2/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 8/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-930470450607.652 total time=   2.9s
[CV 3/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 9/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-37656997227.169 total time=   2.9s
[CV 4/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [CV 7/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   3.0s
[CV 5/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 6/10; 99/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=10, random_state=100, tol=0.01;, score=-263311323007.202 total time=   3.3s
[CV 6/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 5/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-3186185568868.183 total time=   3.8s
[CV 7/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 2/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-3211353460285.229 total time=   4.0s
[CV 8/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 1/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-2309281712602.756 total time=   4.0s
[CV 9/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 6/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-263311323007.202 total time=   4.0s
[CV 10/10; 105/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01
[CV 8/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-930470450607.652 total time=   3.9s
[CV 1/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 9/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-37656997227.169 total time=   3.8s
[CV 2/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 7/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-2045579971968.060 total time=   4.1s
[CV 3/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 2/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-3211353460285.228 total time=   4.0s
[CV 4/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-136182744001.230 total time=   4.3s
[CV 5/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 3/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-286483395630.548 total time=   4.4s
[CV 6/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 10/10; 100/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.0001;, score=-380930465110.889 total time=   4.1s
[CV 7/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 4/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-136182744001.230 total time=   4.2s
[CV 8/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 1/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-2309281712602.755 total time=   4.4s
[CV 9/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 7/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-2045579971968.060 total time=   3.9s
[CV 10/10; 106/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001
[CV 5/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-3186185568868.183 total time=   4.3s
[CV 1/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 6/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-263311323007.202 total time=   4.1s
[CV 2/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 3/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-286483395630.548 total time=   4.6s
[CV 3/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 8/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-930470450607.652 total time=   4.1s
[CV 4/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 9/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-37656997227.169 total time=   4.1s
[CV 5/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 1/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-2309281712602.756 total time=   3.7s
[CV 6/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 10/10; 101/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.001;, score=-380930465110.889 total time=   4.4s
[CV 7/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 4/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-136182744001.230 total time=   4.1s
[CV 8/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 2/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-3211353460285.229 total time=   4.3s
[CV 9/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 7/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-2045579971968.060 total time=   3.9s
[CV 10/10; 107/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001
[CV 2/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-3211353460285.229 total time=   3.9s
[CV 1/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 5/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-3186185568868.183 total time=   4.2s
[CV 2/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 9/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-37656997227.169 total time=   4.0s
[CV 3/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 1/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-2309281712602.755 total time=   3.6s
[CV 4/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 7/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-2045579971968.059 total time=   3.9s
[CV 5/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 8/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-930470450607.653 total time=   4.1s
[CV 6/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 6/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-263311323007.202 total time=   4.2s
[CV 7/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 1/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-2309281712602.757 total time=   4.5s
[CV 8/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 3/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-286483395630.548 total time=   4.5s
[CV 9/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 3/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-286483395630.548 total time=   4.1s
[CV 10/10; 108/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01
[CV 6/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-263311323007.202 total time=   4.1s
[CV 1/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 102/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=0, tol=0.01;, score=-380930465110.889 total time=   4.2s
[CV 2/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-136182744001.230 total time=   4.2s
[CV 3/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 5/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-3186185568868.183 total time=   4.2s
[CV 4/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 10/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-380930465110.889 total time=   4.1s
[CV 5/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 8/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-930470450607.652 total time=   4.2s
[CV 6/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 9/10; 103/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.0001;, score=-37656997227.169 total time=   4.2s
[CV 7/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 4/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-136182744001.230 total time=   4.0s
[CV 8/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 3/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-286483395630.549 total time=   4.0s
[CV 9/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 2/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-3211353460285.228 total time=   4.2s
[CV 10/10; 109/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001
[CV 6/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-263311323007.202 total time=   4.0s
[CV 1/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 5/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-3186185568868.183 total time=   4.1s
[CV 2/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 10/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-380930465110.889 total time=   3.9s
[CV 3/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 8/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-930470450607.652 total time=   4.0s
[CV 4/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 5/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-3186185568868.183 total time=   3.8s
[CV 5/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 9/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-37656997227.169 total time=   4.0s
[CV 6/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 1/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-2309281712602.756 total time=   4.0s
[CV 7/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 3/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-286483395630.548 total time=   4.1s
[CV 8/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 7/10; 104/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.001;, score=-2045579971968.060 total time=   4.3s
[CV 9/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 2/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-3211353460285.229 total time=   4.3s
[CV 10/10; 110/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001
[CV 4/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-136182744001.230 total time=   4.3s
[CV 1/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 6/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-263311323007.202 total time=   4.1s
[CV 2/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 1/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-2309219000441.922 total time=   1.7s
[CV 3/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 2/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-3211330942553.761 total time=   1.8s
[CV 4/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 3/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-286422373961.935 total time=   1.9s
[CV 5/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 7/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-2045579971968.060 total time=   4.0s
[CV 6/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 6/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-263247792386.199 total time=   1.8s
[CV 7/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 8/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-930543882795.614 total time=   1.7s
[CV 8/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 4/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-136118931994.890 total time=   2.0s
[CV 9/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 5/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-3186125016341.296 total time=   2.0s
[CV 10/10; 111/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01
[CV 8/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-930470450607.653 total time=   4.2s
[CV 1/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-37594468474.076 total time=   1.8s
[CV 2/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 10/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-380870744559.435 total time=   1.7s
[CV 3/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 7/10; 109/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.0001;, score=-2045518893039.480 total time=   2.0s
[CV 4/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 9/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-37656997227.169 total time=   4.4s
[CV 5/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 3/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-286422373961.935 total time=   1.9s
[CV 6/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 2/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-3211330942553.760 total time=   1.9s
[CV 7/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 10/10; 105/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=42, tol=0.01;, score=-380930465110.889 total time=   4.4s
[CV 8/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-2309219000441.921 total time=   2.1s
[CV 9/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 6/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-263247792386.199 total time=   1.9s
[CV 10/10; 112/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001
[CV 1/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-2309281712602.756 total time=   4.5s
[CV 1/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 4/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-136118931994.890 total time=   2.0s
[CV 2/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 4/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-136182744001.230 total time=   4.3s
[CV 3/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 7/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-2045518893039.481 total time=   1.9s
[CV 4/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 9/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-37594468474.076 total time=   1.8s
[CV 5/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 6/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-263311323007.202 total time=   4.3s
[CV 6/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 5/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-3186185568868.183 total time=   4.4s
[CV 7/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 3/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-286483395630.548 total time=   4.5s
[CV 8/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 5/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-3186125016341.296 total time=   2.1s
[CV 9/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 2/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-3211353460285.229 total time=   4.7s
[CV 10/10; 113/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001
[CV 10/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-380930465110.889 total time=   4.2s
[CV 1/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 8/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-930470450607.652 total time=   4.3s
[CV 2/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 1/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-2309219000441.922 total time=   1.8s
[CV 3/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 8/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-930543882795.614 total time=   2.1s
[CV 4/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 7/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-2045579971968.060 total time=   4.5s
[CV 5/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 10/10; 110/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.001;, score=-380870744559.435 total time=   2.0s
[CV 6/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 9/10; 106/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.0001;, score=-37656997227.169 total time=   4.4s
[CV 7/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 2/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-3211330942553.761 total time=   2.1s
[CV 8/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 4/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-136182744001.230 total time=   4.4s
[CV 9/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 1/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-2309281712602.755 total time=   4.7s
[CV 10/10; 114/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01
[CV 4/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-136182744001.230 total time=   3.7s
[CV 1/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 9/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-37656997227.169 total time=   3.9s
[CV 2/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 5/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-3186185568868.183 total time=   4.4s
[CV 3/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 2/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-3211353460285.228 total time=   4.8s
[CV 4/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 1/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-2309281712602.755 total time=   4.0s
[CV 5/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-286422373961.935 total time=   2.0s
[CV 6/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 10/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-380930465110.889 total time=   4.1s
[CV 7/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 3/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-286483395630.549 total time=   4.8s
[CV 8/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 9/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-37656997227.169 total time=   3.9s
[CV 9/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 6/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-263311323007.202 total time=   4.3s
[CV 10/10; 115/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001
[CV 7/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-2045579971968.060 total time=   4.2s
[CV 1/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 4/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-136118931994.890 total time=   2.1s
[CV 2/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 5/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-3186125016341.296 total time=   2.0s
[CV 3/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 8/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-930543882795.614 total time=   1.9s
[CV 4/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 5/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-3186185568868.183 total time=   4.2s
[CV 5/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 8/10; 107/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.001;, score=-930470450607.652 total time=   4.4s
[CV 6/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 7/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-2045518893039.481 total time=   2.0s
[CV 7/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 6/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-263311323007.202 total time=   4.2s
[CV 8/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 1/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-2309219000441.922 total time=   1.9s
[CV 9/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 2/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-3211353460285.229 total time=   4.3s
[CV 10/10; 116/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001
[CV 8/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-930470450607.652 total time=   4.2s
[CV 1/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 10/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-380870744559.435 total time=   2.0s
[CV 2/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 4/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-136118931994.890 total time=   1.9s
[CV 3/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 2/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-3211330942553.761 total time=   2.1s
[CV 4/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 9/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-37594468474.076 total time=   2.2s
[CV 5/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 6/10; 111/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=0, tol=0.01;, score=-263247792386.199 total time=   2.4s
[CV 6/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 5/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-3186125016341.296 total time=   1.9s
[CV 7/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 3/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-286422373961.935 total time=   2.1s
[CV 8/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 10/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-380930465110.889 total time=   4.4s
[CV 9/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 2/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-3211330942553.761 total time=   1.8s
[CV 10/10; 117/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01
[CV 3/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-286483395630.548 total time=   4.5s
[CV 1/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 108/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=2, n_init=15, random_state=100, tol=0.01;, score=-2045579971968.060 total time=   4.5s
[CV 2/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 6/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-263247792386.199 total time=   2.0s
[CV 3/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 5/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-3186125016341.296 total time=   1.9s
[CV 4/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 9/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-37594468474.076 total time=   2.1s
[CV 5/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 7/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-2045518893039.481 total time=   2.2s
[CV 6/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 3/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-286422373961.935 total time=   2.0s
[CV 7/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 1/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-2309219000441.922 total time=   2.1s
[CV 8/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 8/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-930543882795.614 total time=   2.2s
[CV 9/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-136118931994.890 total time=   2.0s
[CV 10/10; 118/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001
[CV 4/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-136118931994.890 total time=   1.8s
[CV 1/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 3/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-286422373961.935 total time=   1.9s
[CV 2/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 1/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-2309219000441.922 total time=   1.9s
[CV 3/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 7/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-2045518893039.481 total time=   2.1s
[CV 4/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 6/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-263247792386.199 total time=   1.9s
[CV 5/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 5/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-3186125016341.297 total time=   1.9s
[CV 6/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 2/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-3211330942553.760 total time=   2.0s
[CV 7/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 10/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-380870744559.435 total time=   2.1s
[CV 8/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 6/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-263247792386.199 total time=   2.2s
[CV 9/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 10/10; 112/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.0001;, score=-380870744559.435 total time=   2.4s
[CV 10/10; 119/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001
[CV 8/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-930543882795.614 total time=   2.4s
[CV 1/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 9/10; 113/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.001;, score=-37594468474.076 total time=   2.4s
[CV 2/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 7/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-2045518893039.481 total time=   2.1s
[CV 3/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 4/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-136118931994.890 total time=   1.6s
[CV 4/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 9/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-37594468474.076 total time=   1.4s
[CV 5/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 5/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-3186125016341.296 total time=   1.6s
[CV 6/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 2/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-3211330942553.760 total time=   1.7s
[CV 7/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 1/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-2309219000441.922 total time=   1.7s
[CV 8/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 7/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-2045518893039.481 total time=   1.6s
[CV 9/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 3/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-286422373961.935 total time=   1.7s
[CV 10/10; 120/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01
[CV 8/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-930543882795.614 total time=   2.0s
[CV 1/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-930543882795.614 total time=   1.6s
[CV 2/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-380870744559.435 total time=   1.9s
[CV 3/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 10/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-380870744559.435 total time=   1.6s
[CV 4/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 6/10; 115/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.0001;, score=-263247792386.199 total time=   1.7s
[CV 5/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 4/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-136118931994.890 total time=   1.5s
[CV 6/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 3/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-286422373961.935 total time=   1.5s
[CV 7/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 1/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-2309219000441.921 total time=   1.6s
[CV 8/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 2/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-3211330942553.760 total time=   1.6s
[CV 9/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 117/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-930543882795.615 total time=   1.2s
[CV 10/10; 121/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001
[CV 8/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-930543882795.614 total time=   1.4s
[CV 1/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 5/10; 116/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.001;, score=-3186125016341.296 total time=   1.6s
[CV 2/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 9/10; 114/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=42, tol=0.01;, score=-37594468474.076 total time=   2.1s
[CV 3/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 9/10; 117/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-37594468474.076 total time=   1.2s
[CV 4/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 5/10; 117/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-3186125016341.296 total time=   1.3s
[CV 5/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 7/10; 117/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=5, random_state=100, tol=0.01;, score=-2045518893039.481 total time=   1.3s
[CV 6/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 2/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-3211330942553.760 total time=   1.7s
[CV 7/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 3/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-286422373961.935 total time=   1.7s
[CV 8/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 8/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-930543882795.615 total time=   1.5s
[CV 9/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 10/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-380870744559.435 total time=   1.6s
[CV 10/10; 122/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001
[CV 7/10; 119/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-2045518893039.481 total time=   1.3s
[CV 1/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 6/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-263247792386.199 total time=   1.6s
[CV 2/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 9/10; 118/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.0001;, score=-37594468474.076 total time=   1.6s
[CV 3/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 8/10; 119/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-930543882795.614 total time=   1.3s
[CV 4/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 10/10; 119/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-380870744559.435 total time=   1.3s
[CV 5/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 2/10; 121/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-3211330942553.761 total time=   1.0s
[CV 6/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 9/10; 119/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.001;, score=-37594468474.076 total time=   1.4s
[CV 7/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 7/10; 120/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-2045518893039.481 total time=   1.1s
[CV 8/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 9/10; 120/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=0, tol=0.01;, score=-37594468474.076 total time=   1.1s
[CV 9/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 3/10; 122/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-286422373961.935 total time=   0.9s
[CV 10/10; 123/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01
[CV 2/10; 122/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-3211330942553.761 total time=   1.0s
[CV 1/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 121/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.0001;, score=-2045518893039.481 total time=   1.0s
[CV 2/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 9/10; 122/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-37594468474.076 total time=   0.6s
[CV 3/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 123/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-3211330942553.760 total time=   0.5s
[CV 4/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 10/10; 122/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.001;, score=-380870744559.435 total time=   0.5s
[CV 5/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 3/10; 123/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-286422373961.935 total time=   0.5s
[CV 6/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 7/10; 123/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-2045518893039.481 total time=   0.5s
[CV 7/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 8/10; 123/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=42, tol=0.01;, score=-930543882795.614 total time=   0.5s
[CV 8/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 2/10; 124/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-3211330942553.760 total time=   0.4s
[CV 9/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
[CV 6/10; 124/2430] END algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001;, score=-263247792386.199 total time=   0.2s
[CV 10/10; 124/2430] START algorithm=auto, init=k-means++, max_iter=200, n_clusters=3, n_init=10, random_state=100, tol=0.0001
